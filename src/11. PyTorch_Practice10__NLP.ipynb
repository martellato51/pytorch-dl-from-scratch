{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNGb56/VdF3gAcwydii7c1u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["참고문헌\n","\n","- 파이썬 딥러닝 파이토치 (이경택, 방심수, 안상준 지음), 정보문화사\n","\n","- https://gaussian37.github.io/dl-pytorch-snippets/\n","\n","- 2023 KAIA 한국인공지능학회 / Introduction to pytorch (Hyunchul Kim) / 링크 : https://www.youtube.com/watch?v=YX-AgT-Kovg\n","\n","- PyTorch로 시작하는 딥 러닝 입문 (유원준, 안상준 지음), 링크 : https://wikidocs.net/book/2788"],"metadata":{"id":"u6K6Mjz7crCL"}},{"cell_type":"markdown","source":["# Natural Language Processing (NLP; 자연어 처리)\n"],"metadata":{"id":"2JZebUYWcmA4"}},{"cell_type":"markdown","source":["## 1. NLP 기초\n","\n","NLP는 크게 다음과 같은 세가지 단계로 나누어집니다.\n","\n","1. 문서 전처리 & 토큰화\n","  + 문장/단어(토큰) 단위 분할: 예) 단어 토큰화(영어), 형태소 분석(한국어) 등\n","  + 불용어 제거(Stopwords), 정규화(Normalization): 대소문자 통일, 특수문자 제거 등\n","  + (선택) 형태소 분석(Morphological Analysis), 어간 추출(Stemming), 표제어 추출(Lemmatization): 언어마다 필요한 작업이 달라질 수 있음\n","\n","2. 임베딩(Embedding) 또는 벡터화\n","  + 전처리된 텍스트를 수치화된 벡터로 변환\n","  + 전통 기법: Bag-of-Words, TF-IDF 등(단어 순서를 고려하지 않거나 제한적으로 고려)\n","  + 딥러닝 임베딩: Word2Vec, GloVe 같은 정적(Static) 임베딩, 최근에는 BERT, GPT류의 문맥적(Contextual) 임베딩도 널리 쓰임\n","\n","3. 모델 적용 & 분석\n","  + 벡터화된 텍스트를 AI 모델에 입력하여 결과(분류, 예측 등) 도출\n","  + 예) RNN, LSTM, GRU, 혹은 Transformer 기반 모델을 통해 텍스트 분류, 감성 분석, 번역, 요약 등 다양한 NLP 과제 수행\n","  + 분석 결과(예측값, 확률 등)에 대해 평가 지표(정확도, F1 점수 등) 확인"],"metadata":{"id":"aZxMn3i_UNlw"}},{"cell_type":"markdown","source":["### (Step 1) 전처리 & 토큰화\n","\n","- 자연어를 전처리 및 토큰화하는 과정을 간략하게 살펴본다.\n","- 일반적으로 토큰화, 단어 집합 생성, 정수 인코딩, 패딩, 벡터화의 과정을 거친다."],"metadata":{"id":"GusuQ15-zIFC"}},{"cell_type":"markdown","source":["#### (a) 토큰화 (Tokenization)\n","\n","- 토큰화 (Tokenization) : 주어진 텍스트를 단어 또는 문자 단위로 자르는 것\n","- 영어의 경우 토큰화를 사용하는 도구로는 `spaCy`와 `NLTK`등이 있다.\n","  +  다만 요즘 딥러닝 기반 NLP가 확산되면서 Transformer 모델(예: BERT, GPT 등)에서 제공하는 **서브워드 토크나이저(WordPiece, SentencePiece, BPE 등)**가 주로 사용되고 있습니다.\n","    + (예시) \"unwanted\" -> “un + ##want + ##ed” 같은 식으로 쪼개어 (기존에 학습된 조각들)로 표현\n","- en_text = \"A Dog Run back corner near spare bedrooms\" 에 대해서 다음과 같이 토큰화를 할 수 있습니다"],"metadata":{"id":"j_fv1BHsBcND"}},{"cell_type":"code","source":["en_text = \"A Dog Run back corner near spare bedrooms\""],"metadata":{"id":"soRceVgJBfvz","executionInfo":{"status":"ok","timestamp":1735298181719,"user_tz":-540,"elapsed":409,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# 방법 1. spaCy 사용하기\n","import spacy\n","spacy_en = spacy.load('en_core_web_sm')\n","\n","def tokenize(en_text):\n","    return [tok.text for tok in spacy_en.tokenizer(en_text)]\n","\n","print(tokenize(en_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1xOQkByBhd7","executionInfo":{"status":"ok","timestamp":1735298191477,"user_tz":-540,"elapsed":4719,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"3e43f6a8-a24c-4eba-e090-bcf6825713d6"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']\n"]}]},{"cell_type":"code","source":["# 방법 2. NLTK 사용하기\n","import nltk\n","nltk.download('punkt_tab')\n","from nltk.tokenize import TreebankWordTokenizer\n","\n","tokenizer = TreebankWordTokenizer()\n","\n","print(tokenizer.tokenize(en_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7OTXCF1X0dhF","executionInfo":{"status":"ok","timestamp":1735298202471,"user_tz":-540,"elapsed":3351,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"f595974b-6f3b-40ef-dc3b-9ecb37057930"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"code","source":["# 방법 3. 띄어쓰기로 토큰화\n","print(en_text.split())"],"metadata":{"id":"Q2oSSgMf3lHN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735298206318,"user_tz":-540,"elapsed":405,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"7cceb483-ad27-4d58-e1f1-b62b0371667a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['A', 'Dog', 'Run', 'back', 'corner', 'near', 'spare', 'bedrooms']\n"]}]},{"cell_type":"markdown","source":["- 사실 영어의 경우에는 띄어쓰기 단위로 토큰화를 해도 단어들 간 구분이 꽤나 명확하기 때문에, 토큰화 작업이 수월합니다.\n","- 하지만 한국어의 경우에는 토큰화 작업이 훨씬 까다롭습니다.\n","- 그 이유는 한국어는 조사, 접사 등으로 인해 단순 띄어쓰기 단위로 나누면 같은 단어가 다른 단어로 인식되어서 단어 집합(vocabulary)의 크기가 불필요하게 커지기 때문입니다.\n","  + 단어 집합(vocabuary)이란 중복을 제거한 텍스트의 총 단어의 집합(set)을 의미\n","- 예를 들어 단어 '사과'가 많이 들어간 어떤 문장에 띄어쓰기 토큰화를 한다면 '사과가', '사과를', '사과의', '사과와', '사과는'과 같은 식으로 같은 단어임에도 조사가 붙어서 다른 단어로 인식될 수 있습니다."],"metadata":{"id":"122LrN9K3pKF"}},{"cell_type":"code","source":["# 한국어 - 방법 1.  한국어 띄어쓰기 토큰화\n","kor_text = \"사과의 놀라운 효능이라는 글을 봤어. 그래서 오늘 사과를 먹으려고 했는데 사과가 썩어서 슈퍼에 가서 사과랑 오렌지 사왔어\"\n","print(kor_text.split())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjiQBpqB36SR","executionInfo":{"status":"ok","timestamp":1735298221726,"user_tz":-540,"elapsed":429,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"77507009-dae7-459b-f661-9ecc7bacd431"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['사과의', '놀라운', '효능이라는', '글을', '봤어.', '그래서', '오늘', '사과를', '먹으려고', '했는데', '사과가', '썩어서', '슈퍼에', '가서', '사과랑', '오렌지', '사왔어']\n"]}]},{"cell_type":"markdown","source":["- '사과'란 단어가 총 4번 등장했는데 모두 '의', '를', '가', '랑' 등이 붙어있어 이를 제거해주지 않으면 기계는 전부 다른 단어로 인식하게 됩니다."],"metadata":{"id":"6SxM8iWB4DAF"}},{"cell_type":"markdown","source":["- 위와 같은 상황을 방지하기 위해서 한국어는 보편적으로 **형태소 분석기**로 토큰화\n","  + `mecab`을 활용한 예시 :"],"metadata":{"id":"NNYrp7BC4doF"}},{"cell_type":"code","source":["!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n","%cd Mecab-ko-for-Google-Colab\n","!bash install_mecab-ko_on_colab_light_220429.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EAC4FUz5tPR","executionInfo":{"status":"ok","timestamp":1735298404127,"user_tz":-540,"elapsed":174310,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"cff7fc2e-4dda-421d-e75c-d318c7367dc8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Mecab-ko-for-Google-Colab'...\n","remote: Enumerating objects: 138, done.\u001b[K\n","remote: Counting objects: 100% (47/47), done.\u001b[K\n","remote: Compressing objects: 100% (38/38), done.\u001b[K\n","remote: Total 138 (delta 26), reused 22 (delta 8), pack-reused 91 (from 1)\u001b[K\n","Receiving objects: 100% (138/138), 1.72 MiB | 6.89 MiB/s, done.\n","Resolving deltas: 100% (65/65), done.\n","/content/Mecab-ko-for-Google-Colab\n","Installing konlpy.....\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting JPype1>=0.7.0 (from konlpy)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (5.3.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n","Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.1 konlpy-0.6.0\n","Done\n","Installing mecab-0.996-ko-0.9.2.tar.gz.....\n","Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","--2024-12-27 11:17:15--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 13.200.41.135, 13.200.41.134, 13.200.41.136, ...\n","Connecting to bitbucket.org (bitbucket.org)|13.200.41.135|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNOJ4EVERE&Signature=U5k2drAvgmnntIS03oxQiGUFzDE%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEGwaCXVzLWVhc3QtMSJGMEQCIAw6%2FH8e2fHj7N01wxufMwsMUY%2BRlPsCIWyTXR6VKXMwAiAsD%2F9Iy%2FTGggEramAy%2FYrNdjX%2FFUHwOgwmusDNLmsYTyqnAghEEAAaDDk4NDUyNTEwMTE0NiIMstvhB%2BjnPbXNE9gaKoQCky3kYx4uZkZwMbcDvcNlR0FeNHoRqe46HyGTmir5aYfhEEeQaxJv0P4VjqGGIYeDh262mrkevrxEtEOZKkKMP9a9168j74%2F39mHrEeGCoZNVSGiH3FK%2FA%2B43b%2BBW0ajwuYkI2dkAJ697n09Jm5V%2F3CqvlxpSjVoCtrQsNTfM5t8%2Bc537YI7Agbn4pSRCYgDmN9CQ02EpYJlDoKEgCczkzDHDHI6R0c7bHIr2UTY8q%2BlCYnXNsJF%2BhArjdI0cUgDW1sZm9P%2F5xGoD4D67jrGqBcQUOsiV4vGalCo3diwu7vi6yxXU4GL3q3gw0aZXFz4CSg%2F8bxbBTHmOl7lT6p4YMOVtRyYwvJm6uwY6ngHDlaFmsiUKhixCsWWSITqJlpVPGbDmEnl50dFZbM9QelPb4y7lwwymF0RSdO5BbYI1%2Fy46JkQrT3RFHW4e1YHYWW5%2BGBnmLMwpDqeld6JgxNKAfLU6koOn76nHzm35KB5gCanFmCo6ZnCGKOo1%2FufV11s32pRNcn%2FCxhESgKdABAjzTuQDkHyxKRFHeqBExpDmNzKJZ%2BAuLsiHPPOOEQ%3D%3D&Expires=1735300036 [following]\n","--2024-12-27 11:17:16--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNOJ4EVERE&Signature=U5k2drAvgmnntIS03oxQiGUFzDE%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEGwaCXVzLWVhc3QtMSJGMEQCIAw6%2FH8e2fHj7N01wxufMwsMUY%2BRlPsCIWyTXR6VKXMwAiAsD%2F9Iy%2FTGggEramAy%2FYrNdjX%2FFUHwOgwmusDNLmsYTyqnAghEEAAaDDk4NDUyNTEwMTE0NiIMstvhB%2BjnPbXNE9gaKoQCky3kYx4uZkZwMbcDvcNlR0FeNHoRqe46HyGTmir5aYfhEEeQaxJv0P4VjqGGIYeDh262mrkevrxEtEOZKkKMP9a9168j74%2F39mHrEeGCoZNVSGiH3FK%2FA%2B43b%2BBW0ajwuYkI2dkAJ697n09Jm5V%2F3CqvlxpSjVoCtrQsNTfM5t8%2Bc537YI7Agbn4pSRCYgDmN9CQ02EpYJlDoKEgCczkzDHDHI6R0c7bHIr2UTY8q%2BlCYnXNsJF%2BhArjdI0cUgDW1sZm9P%2F5xGoD4D67jrGqBcQUOsiV4vGalCo3diwu7vi6yxXU4GL3q3gw0aZXFz4CSg%2F8bxbBTHmOl7lT6p4YMOVtRyYwvJm6uwY6ngHDlaFmsiUKhixCsWWSITqJlpVPGbDmEnl50dFZbM9QelPb4y7lwwymF0RSdO5BbYI1%2Fy46JkQrT3RFHW4e1YHYWW5%2BGBnmLMwpDqeld6JgxNKAfLU6koOn76nHzm35KB5gCanFmCo6ZnCGKOo1%2FufV11s32pRNcn%2FCxhESgKdABAjzTuQDkHyxKRFHeqBExpDmNzKJZ%2BAuLsiHPPOOEQ%3D%3D&Expires=1735300036\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 3.5.27.130, 52.216.95.75, 16.182.36.41, ...\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|3.5.27.130|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1414979 (1.3M) [application/x-tar]\n","Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n","\n","mecab-0.996-ko-0.9. 100%[===================>]   1.35M  1.19MB/s    in 1.1s    \n","\n","2024-12-27 11:17:18 (1.19 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n","\n","Done\n","Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n","Done\n","Change Directory to mecab-0.996-ko-0.9.2.......\n","installing mecab-0.996-ko-0.9.2.tar.gz........\n","configure\n","make\n","\n","make check\n","make install\n","ldconfig\n","Done\n","Change Directory to /content\n","Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","--2024-12-27 11:19:27--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 13.200.41.136, 13.200.41.135, 13.200.41.134, ...\n","Connecting to bitbucket.org (bitbucket.org)|13.200.41.136|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKVJTEAF4&Signature=u%2BWF%2BKNhbG8WPegLPJaOijCs2WI%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEGwaCXVzLWVhc3QtMSJHMEUCIQDNG6csnSs35VMCeBWK3Ca7Qk0MkoV%2FQUUw0RbaScKy%2FgIgAuB8arYnPo6R9hoTepi56I%2FphPgzIIIuQYUGf5j39doqpwIIRBAAGgw5ODQ1MjUxMDExNDYiDHgHqB2IgG56q2kyASqEAo1szG6BJS8yiGqZemmDD6ZA7rPkWSDtVrlrnZ7tOOoUrJghv9wovDuvBMVOirpdqIkpu72XLntA0iSVPFhFM6V%2FGlBhKndVk9vInlPl4GjC9uvMQo8OeM7NljZ%2FdZBwjIxOmq%2BYbdtIKP186jTdJ5SOKlLogeOdeR62SxxuggvRSlsUYCFxVya21LjZjnf2cgdxwv5ij0zIVNZkJ3PO7NPocZTJ6tvVZbpHBF8ccI%2FDehc297kG7Ed0kA2xoZ7wCfWorg5Q14Dg6nw5XaLIOgHbBC5%2B%2BwlsLwcUpttKPdNiVjcmW2H%2BK7ooMoLm%2FmCegw%2Bx%2BCG7GraLww6lIxc6chDihO%2FhMOeZursGOp0BfiEjECd8VFZLS%2Bp%2FcGAR04KHUC5sH7Q1tp6SGyStLWgKnKdElnL%2Fu5v1SZHcCG06RXZHYnWz2E1ylzE0O%2FVosQVrn6D8ilhpwxjj5witHnG7uYl9DHhsCMGn8j7iJtp%2Bho8Yvv4xcfceIDzOurdhkJ4TbhKKfff%2BINzK4Fbk8iVjWArIYAB0yF%2BcQOORjyshbKROloKvgtr%2BftIPLg%3D%3D&Expires=1735300079 [following]\n","--2024-12-27 11:19:28--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNKVJTEAF4&Signature=u%2BWF%2BKNhbG8WPegLPJaOijCs2WI%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEGwaCXVzLWVhc3QtMSJHMEUCIQDNG6csnSs35VMCeBWK3Ca7Qk0MkoV%2FQUUw0RbaScKy%2FgIgAuB8arYnPo6R9hoTepi56I%2FphPgzIIIuQYUGf5j39doqpwIIRBAAGgw5ODQ1MjUxMDExNDYiDHgHqB2IgG56q2kyASqEAo1szG6BJS8yiGqZemmDD6ZA7rPkWSDtVrlrnZ7tOOoUrJghv9wovDuvBMVOirpdqIkpu72XLntA0iSVPFhFM6V%2FGlBhKndVk9vInlPl4GjC9uvMQo8OeM7NljZ%2FdZBwjIxOmq%2BYbdtIKP186jTdJ5SOKlLogeOdeR62SxxuggvRSlsUYCFxVya21LjZjnf2cgdxwv5ij0zIVNZkJ3PO7NPocZTJ6tvVZbpHBF8ccI%2FDehc297kG7Ed0kA2xoZ7wCfWorg5Q14Dg6nw5XaLIOgHbBC5%2B%2BwlsLwcUpttKPdNiVjcmW2H%2BK7ooMoLm%2FmCegw%2Bx%2BCG7GraLww6lIxc6chDihO%2FhMOeZursGOp0BfiEjECd8VFZLS%2Bp%2FcGAR04KHUC5sH7Q1tp6SGyStLWgKnKdElnL%2Fu5v1SZHcCG06RXZHYnWz2E1ylzE0O%2FVosQVrn6D8ilhpwxjj5witHnG7uYl9DHhsCMGn8j7iJtp%2Bho8Yvv4xcfceIDzOurdhkJ4TbhKKfff%2BINzK4Fbk8iVjWArIYAB0yF%2BcQOORjyshbKROloKvgtr%2BftIPLg%3D%3D&Expires=1735300079\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.83.140, 3.5.17.139, 3.5.8.19, ...\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.83.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 49775061 (47M) [application/x-tar]\n","Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n","\n","mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  12.5MB/s    in 4.2s    \n","\n","2024-12-27 11:19:33 (11.4 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n","\n","Done\n","Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","Done\n","Change Directory to mecab-ko-dic-2.1.1-20180720\n","Done\n","installing........\n","configure\n","make\n","make install\n","bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n","https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n","Done\n","Install mecab-python\n","Successfully Installed\n","Now you can use Mecab\n","from konlpy.tag import Mecab\n","mecab = Mecab()\n","사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n","NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n","블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n","light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n","문제를 해결해주신 combacsa님 감사합니다.\n"]}]},{"cell_type":"code","source":["# 한국어 - 방법 2. 형태소 토큰화\n","from konlpy.tag import Mecab\n","tokenizer = Mecab()\n","print(tokenizer.morphs(kor_text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXWRUFMD4FB5","executionInfo":{"status":"ok","timestamp":1735298430365,"user_tz":-540,"elapsed":422,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"1a415dea-79a1-41c6-98d4-cbe7c8f36fa1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['사과', '의', '놀라운', '효능', '이', '라는', '글', '을', '봤', '어', '.', '그래서', '오늘', '사과', '를', '먹', '으려고', '했', '는데', '사과', '가', '썩', '어서', '슈퍼', '에', '가', '서', '사과', '랑', '오렌지', '사', '왔', '어']\n"]}]},{"cell_type":"markdown","source":["- 이 외에도 자연어를 토큰화할 때는 다른 전처리 과정이 다수 포함됩니다. 예를 들어, 정제, 정규화, 불용어 처리 등이 있습니다.\n","  + 정제(cleaning) : 노이즈 데이터를 제거한다.\n","    + (예시) 자연어가 아니면서 아무 의미도 갖지 않는 글자들(특수 문자 등) 혹은 등장 빈도가 적은 단어 등\n","  + 정규화(normalization) : 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만들어준다.\n","    + (예시) US = USA 혹은 대문자 소문자 통합 등\n","  + 불용어 처리 : 큰 의미가 없는 단어 토큰을 제거\n","    + 한국어에 대한 형태소 토큰화를 한 이후, '의', '이' 등의 조사 제거 등\n"],"metadata":{"id":"XTqlVMwI27we"}},{"cell_type":"markdown","source":["### (b) 단어 집합(Vocabulary) 생성\n","\n","- 단어 집합(vocabuary)이란 중복을 제거한 텍스트의 총 단어의 집합(set)을 의미합니다. - 실습을 위해서 깃허브에서 '네이버 영화 리뷰 분류하기' 데이터를 다운로드하겠습니다.\n","  + 네이버 영화 리뷰 데이터는 총 20만 개의 영화 리뷰를 긍정 1, 부정 0으로 레이블링한 데이터입니다."],"metadata":{"id":"nK-rndtZ6Zd6"}},{"cell_type":"code","source":["import urllib.request\n","import pandas as pd\n","from konlpy.tag import Mecab\n","from nltk import FreqDist\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"I1KDskyw6fMP","executionInfo":{"status":"ok","timestamp":1735298882835,"user_tz":-540,"elapsed":420,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n","data = pd.read_table('ratings.txt') # 데이터프레임에 저장\n","data[:10]"],"metadata":{"id":"VoBKBtWs6gS4","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1735298888162,"user_tz":-540,"elapsed":3581,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"f210f79e-a360-4496-c395-ee6bec3a3e6f"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n","1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n","2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n","3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n","4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1\n","5   2190435                      사랑을 해본사람이라면 처음부터 끝까지 웃을수 있는영화      1\n","6   9279041                                   완전 감동입니다 다시봐도 감동      1\n","7   7865729                        개들의 전쟁2 나오나요? 나오면 1빠로 보고 싶음      1\n","8   7477618                                                  굿      1\n","9   9250537                                     바보가 아니라 병 쉰 인듯      1"],"text/html":["\n","  <div id=\"df-6aaf2117-84f9-4438-b25a-0ad8d469cdb1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8112052</td>\n","      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8132799</td>\n","      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4655635</td>\n","      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9251303</td>\n","      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10067386</td>\n","      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2190435</td>\n","      <td>사랑을 해본사람이라면 처음부터 끝까지 웃을수 있는영화</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>9279041</td>\n","      <td>완전 감동입니다 다시봐도 감동</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7865729</td>\n","      <td>개들의 전쟁2 나오나요? 나오면 1빠로 보고 싶음</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7477618</td>\n","      <td>굿</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9250537</td>\n","      <td>바보가 아니라 병 쉰 인듯</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aaf2117-84f9-4438-b25a-0ad8d469cdb1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6aaf2117-84f9-4438-b25a-0ad8d469cdb1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6aaf2117-84f9-4438-b25a-0ad8d469cdb1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-14ba3101-1eac-4b81-a554-6b961066806f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14ba3101-1eac-4b81-a554-6b961066806f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-14ba3101-1eac-4b81-a554-6b961066806f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"data[:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2424747,\n        \"min\": 2190435,\n        \"max\": 10067386,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7477618,\n          8132799,\n          2190435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\uad7f\",\n          \"\\ub514\\uc790\\uc778\\uc744 \\ubc30\\uc6b0\\ub294 \\ud559\\uc0dd\\uc73c\\ub85c, \\uc678\\uad6d\\ub514\\uc790\\uc774\\ub108\\uc640 \\uadf8\\ub4e4\\uc774 \\uc77c\\uad70 \\uc804\\ud1b5\\uc744 \\ud1b5\\ud574 \\ubc1c\\uc804\\ud574\\uac00\\ub294 \\ubb38\\ud654\\uc0b0\\uc5c5\\uc774 \\ubd80\\ub7ec\\uc6e0\\ub294\\ub370. \\uc0ac\\uc2e4 \\uc6b0\\ub9ac\\ub098\\ub77c\\uc5d0\\uc11c\\ub3c4 \\uadf8 \\uc5b4\\ub824\\uc6b4\\uc2dc\\uc808\\uc5d0 \\ub05d\\uae4c\\uc9c0 \\uc5f4\\uc815\\uc744 \\uc9c0\\ud0a8 \\ub178\\ub77c\\ub178 \\uac19\\uc740 \\uc804\\ud1b5\\uc774\\uc788\\uc5b4 \\uc800\\uc640 \\uac19\\uc740 \\uc0ac\\ub78c\\ub4e4\\uc774 \\uafc8\\uc744 \\uafb8\\uace0 \\uc774\\ub904\\ub098\\uac08 \\uc218 \\uc788\\ub2e4\\ub294 \\uac83\\uc5d0 \\uac10\\uc0ac\\ud569\\ub2c8\\ub2e4.\",\n          \"\\uc0ac\\ub791\\uc744 \\ud574\\ubcf8\\uc0ac\\ub78c\\uc774\\ub77c\\uba74 \\ucc98\\uc74c\\ubd80\\ud130 \\ub05d\\uae4c\\uc9c0 \\uc6c3\\uc744\\uc218 \\uc788\\ub294\\uc601\\ud654\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["print('전체 샘플의 수 : {}'.format(len(data)))"],"metadata":{"id":"ocR-pVvp6iIC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735298892286,"user_tz":-540,"elapsed":435,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"d3f403e7-fed7-49ae-9480-485664ab10fd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 샘플의 수 : 200000\n"]}]},{"cell_type":"code","source":["sample_data = data[:100] # 임의로 100개만 저장"],"metadata":{"id":"Bzo_bLIL6jhK","executionInfo":{"status":"ok","timestamp":1735298894204,"user_tz":-540,"elapsed":805,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["정규 표현식을 통해서 데이터를 정제합니다.\n","\n","- 언어 모델을 사용할 때는 전처리로 정제(cleaning; 갖고 있는 코퍼스로부터 노이즈 데이터를 제거)와 정규화(normalization; 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 변화)가 필요\n","  + 예를 들어, USA와 US는 같은 의미를 가지므로 하나의 단어로 정규화\n","- 정규 표현식은 이러한 코퍼스 내에 계속해서 등장하는 글자들을 규칙에 기반하여 한 번에 제거하는 방식으로서 매우 유용"],"metadata":{"id":"OCAlaUSV9ToK"}},{"cell_type":"code","source":["# 정규 표현식을 통해서 데이터를 정제합니다.\n","sample_data['document'] = sample_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)\n","# 한글과 공백을 제외하고 모두 제거\n","\n","sample_data[:10]"],"metadata":{"id":"HtrduVh26lT2","colab":{"base_uri":"https://localhost:8080/","height":475},"executionInfo":{"status":"ok","timestamp":1735298901561,"user_tz":-540,"elapsed":435,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"7e426cd2-57e5-497e-e900-4b1f994a8f93"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-8291604f3626>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  sample_data['document'] = sample_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n","1   8132799  디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...      1\n","2   4655635                   폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고      1\n","3   9251303   와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지      1\n","4  10067386                         안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화      1\n","5   2190435                      사랑을 해본사람이라면 처음부터 끝까지 웃을수 있는영화      1\n","6   9279041                                   완전 감동입니다 다시봐도 감동      1\n","7   7865729                           개들의 전쟁 나오나요 나오면 빠로 보고 싶음      1\n","8   7477618                                                  굿      1\n","9   9250537                                     바보가 아니라 병 쉰 인듯      1"],"text/html":["\n","  <div id=\"df-a09e48ee-2223-4389-a755-1980f450b922\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8112052</td>\n","      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8132799</td>\n","      <td>디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4655635</td>\n","      <td>폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9251303</td>\n","      <td>와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10067386</td>\n","      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2190435</td>\n","      <td>사랑을 해본사람이라면 처음부터 끝까지 웃을수 있는영화</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>9279041</td>\n","      <td>완전 감동입니다 다시봐도 감동</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7865729</td>\n","      <td>개들의 전쟁 나오나요 나오면 빠로 보고 싶음</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7477618</td>\n","      <td>굿</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9250537</td>\n","      <td>바보가 아니라 병 쉰 인듯</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a09e48ee-2223-4389-a755-1980f450b922')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a09e48ee-2223-4389-a755-1980f450b922 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a09e48ee-2223-4389-a755-1980f450b922');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bf1af3b5-8f9b-4df8-8f07-d2e53df89767\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf1af3b5-8f9b-4df8-8f07-d2e53df89767')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bf1af3b5-8f9b-4df8-8f07-d2e53df89767 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"sample_data[:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2424747,\n        \"min\": 2190435,\n        \"max\": 10067386,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7477618,\n          8132799,\n          2190435\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\uad7f\",\n          \"\\ub514\\uc790\\uc778\\uc744 \\ubc30\\uc6b0\\ub294 \\ud559\\uc0dd\\uc73c\\ub85c \\uc678\\uad6d\\ub514\\uc790\\uc774\\ub108\\uc640 \\uadf8\\ub4e4\\uc774 \\uc77c\\uad70 \\uc804\\ud1b5\\uc744 \\ud1b5\\ud574 \\ubc1c\\uc804\\ud574\\uac00\\ub294 \\ubb38\\ud654\\uc0b0\\uc5c5\\uc774 \\ubd80\\ub7ec\\uc6e0\\ub294\\ub370 \\uc0ac\\uc2e4 \\uc6b0\\ub9ac\\ub098\\ub77c\\uc5d0\\uc11c\\ub3c4 \\uadf8 \\uc5b4\\ub824\\uc6b4\\uc2dc\\uc808\\uc5d0 \\ub05d\\uae4c\\uc9c0 \\uc5f4\\uc815\\uc744 \\uc9c0\\ud0a8 \\ub178\\ub77c\\ub178 \\uac19\\uc740 \\uc804\\ud1b5\\uc774\\uc788\\uc5b4 \\uc800\\uc640 \\uac19\\uc740 \\uc0ac\\ub78c\\ub4e4\\uc774 \\uafc8\\uc744 \\uafb8\\uace0 \\uc774\\ub904\\ub098\\uac08 \\uc218 \\uc788\\ub2e4\\ub294 \\uac83\\uc5d0 \\uac10\\uc0ac\\ud569\\ub2c8\\ub2e4\",\n          \"\\uc0ac\\ub791\\uc744 \\ud574\\ubcf8\\uc0ac\\ub78c\\uc774\\ub77c\\uba74 \\ucc98\\uc74c\\ubd80\\ud130 \\ub05d\\uae4c\\uc9c0 \\uc6c3\\uc744\\uc218 \\uc788\\ub294\\uc601\\ud654\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["토큰화를 수행해보겠습니다. 토큰화 과정에서 불용어를 제거하기 위해 불용어를 우선 정의합니다.\n","\n","- 자주 등장하지만 분석을 하는 것에 있어서는 큰 도움이 되지 않는 단어인 불용어를 제거."],"metadata":{"id":"wCFah_TB9VHa"}},{"cell_type":"code","source":["# 불용어 정의\n","stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"],"metadata":{"id":"vGYWJ-Jy6vFr","executionInfo":{"status":"ok","timestamp":1735298952654,"user_tz":-540,"elapsed":566,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["형태소 분석기는 mecab을 사용합니다."],"metadata":{"id":"ZLJTavrl9Xsu"}},{"cell_type":"code","source":["tokenizer = Mecab()\n","tokenized=[]\n","for sentence in sample_data['document']:\n","    temp = tokenizer.morphs(sentence) # 토큰화\n","    temp = [word for word in temp if not word in stopwords] # 불용어 제거\n","    tokenized.append(temp)\n","\n","print(tokenized[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zJ98bMcm9YA6","executionInfo":{"status":"ok","timestamp":1735298955325,"user_tz":-540,"elapsed":629,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"1bd541cf-e1a1-4601-ad6d-f5ad687e84b1"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[['어릴', '때', '보', '고', '지금', '다시', '봐도', '재밌', '어요', 'ㅋㅋ'], ['디자인', '을', '배우', '학생', '외국', '디자이너', '그', '일군', '전통', '을', '통해', '발전', '해', '문화', '산업', '부러웠', '는데', '사실', '우리', '나라', '에서', '그', '어려운', '시절', '끝', '까지', '열정', '을', '지킨', '노라노', '같', '전통', '있', '어', '저', '같', '사람', '꿈', '을', '꾸', '고', '이뤄나갈', '수', '있', '다는', '것', '감사', '합니다'], ['폴리스', '스토리', '시리즈', '부터', '뉴', '까지', '버릴', '께', '하나', '없', '음', '최고'], ['연기', '진짜', '개', '쩔', '구나', '지루', '할거', '라고', '생각', '했', '는데', '몰입', '해서', '봤', '다', '그래', '이런', '게', '진짜', '영화', '지'], ['안개', '자욱', '밤하늘', '떠', '있', '초승달', '같', '영화'], ['사랑', '을', '해', '본', '사람', '라면', '처음', '부터', '끝', '까지', '웃', '을', '수', '있', '영화'], ['완전', '감동', '입니다', '다시', '봐도', '감동'], ['개', '전쟁', '나오', '나요', '나오', '면', '빠', '로', '보', '고', '싶', '음'], ['굿'], ['바보', '아니', '라', '병', '쉰', '인', '듯']]\n"]}]},{"cell_type":"markdown","source":["이제 단어 집합을 만들어봅시다. NLTK에서는 빈도수 계산 도구인 `FreqDist()`를 지원합니다."],"metadata":{"id":"V-k4ccHF9hnK"}},{"cell_type":"code","source":["vocab = FreqDist(np.hstack(tokenized))\n","print('단어 집합의 크기 : {}'.format(len(vocab)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKRNc6WN9g-O","executionInfo":{"status":"ok","timestamp":1735298959324,"user_tz":-540,"elapsed":424,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"25098c13-7f0d-40f4-d147-be536582e877"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합의 크기 : 664\n"]}]},{"cell_type":"markdown","source":["단어를 키(key)로, 단어에 대한 빈도수가 값(value)으로 저장되어져 있습니다. vocab에 단어를 입력하면 빈도수를 리턴합니다."],"metadata":{"id":"Mjjmp72z9rB6"}},{"cell_type":"code","source":["vocab['재밌']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCPsPPV39p76","executionInfo":{"status":"ok","timestamp":1735298964183,"user_tz":-540,"elapsed":418,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"b6642126-2de1-46ca-86f0-1834e57f6b69"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["'재밌'이란 단어가 총 10번 등장하였습니다. `most_common()`는 상위 빈도수를 가진 주어진 수의 단어만을 리턴합니다. 이를 사용하여 등장 빈도수가 높은 단어들을 원하는 개수만큼만 얻을 수 있습니다. 등장 빈도수 상위 500개의 단어만 단어 집합으로 저장해봅시다."],"metadata":{"id":"vokM5QXq9uBW"}},{"cell_type":"code","source":["vocab_size = 500 # 600\n","# 상위 vocab_size개의 단어만 보존\n","vocab = vocab.most_common(vocab_size)\n","print('단어 집합의 크기 : {}'.format(len(vocab)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWyiJmYX9xib","executionInfo":{"status":"ok","timestamp":1735298967618,"user_tz":-540,"elapsed":378,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"d7f0803b-7f8a-4b3b-9f30-74eaa7c6fb23"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합의 크기 : 500\n"]}]},{"cell_type":"markdown","source":["단어 집합의 크기가 500으로 줄어든 것을 확인할 수 있습니다."],"metadata":{"id":"W4z2ilGT9zg7"}},{"cell_type":"markdown","source":["### (c) 각 단어에 고유한 정수 부여\n","\n","- enumerate()는 순서가 있는 자료형(list, set, tuple, dictionary, string)을 입력으로 받아 인덱스를 순차적으로 함께 리턴한다는 특징이 있습니다.\n","- 인덱스 0과 1은 다른 용도로 남겨두고 나머지 단어들은 2부터 501까지 순차적으로 인덱스를 부여해봅시다."],"metadata":{"id":"u3ona2vN92He"}},{"cell_type":"code","source":["word_to_index = {word[0] : index + 2 for index, word in enumerate(vocab)}\n","word_to_index['pad'] = 1\n","word_to_index['unk'] = 0\n","\n","# 문장의 길이를 맞추기 위한 [pad]\n","# 없는 글자를 처리하기 위한 [unk]\n","word_to_index"],"metadata":{"id":"pOEkb4Yc9-Xq","executionInfo":{"status":"ok","timestamp":1735298975769,"user_tz":-540,"elapsed":419,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ced95afb-231d-40d3-cb7f-363138fa9a00"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'다': 2,\n"," '영화': 3,\n"," '고': 4,\n"," '을': 5,\n"," '하': 6,\n"," '있': 7,\n"," '게': 8,\n"," '보': 9,\n"," '없': 10,\n"," '최고': 11,\n"," '좋': 12,\n"," '는데': 13,\n"," '수': 14,\n"," '봤': 15,\n"," '재밌': 16,\n"," '같': 17,\n"," '적': 18,\n"," '할': 19,\n"," '었': 20,\n"," '내': 21,\n"," '만': 22,\n"," '정말': 23,\n"," '해': 24,\n"," '음': 25,\n"," '였': 26,\n"," '때': 27,\n"," '어요': 28,\n"," 'ㅋㅋ': 29,\n"," '에서': 30,\n"," '까지': 31,\n"," '것': 32,\n"," '진짜': 33,\n"," '했': 34,\n"," '지': 35,\n"," '본': 36,\n"," '감동': 37,\n"," '로': 38,\n"," '아': 39,\n"," '네요': 40,\n"," '너무': 41,\n"," '다시': 42,\n"," '그': 43,\n"," '사람': 44,\n"," '연기': 45,\n"," '생각': 46,\n"," '싶': 47,\n"," '나': 48,\n"," '으면': 49,\n"," '지금': 50,\n"," '사실': 51,\n"," '저': 52,\n"," '부터': 53,\n"," '하나': 54,\n"," '나오': 55,\n"," '굿': 56,\n"," '인': 57,\n"," '왜': 58,\n"," '네': 59,\n"," '년': 60,\n"," '마음': 61,\n"," '말': 62,\n"," '거': 63,\n"," '재미있': 64,\n"," '뭐': 65,\n"," '지만': 66,\n"," '중': 67,\n"," '어': 68,\n"," '라고': 69,\n"," '이런': 70,\n"," '았': 71,\n"," '평점': 72,\n"," '된': 73,\n"," '기': 74,\n"," '속': 75,\n"," '면서': 76,\n"," '주': 77,\n"," '건': 78,\n"," '어릴': 79,\n"," '봐도': 80,\n"," '배우': 81,\n"," '우리': 82,\n"," '다는': 83,\n"," '합니다': 84,\n"," '웃': 85,\n"," '면': 86,\n"," '아니': 87,\n"," '라': 88,\n"," '듯': 89,\n"," '낮': 90,\n"," '인데': 91,\n"," '서': 92,\n"," '던': 93,\n"," '마지막': 94,\n"," '대한': 95,\n"," '명작': 96,\n"," '될': 97,\n"," '는지': 98,\n"," '어디': 99,\n"," '안': 100,\n"," '볼': 101,\n"," '이거': 102,\n"," '친구': 103,\n"," '또': 104,\n"," '방': 105,\n"," '재미': 106,\n"," '느낌': 107,\n"," '남자': 108,\n"," '되': 109,\n"," '매력': 110,\n"," 'ㅎ': 111,\n"," '습니다': 112,\n"," '전통': 113,\n"," '문화': 114,\n"," '나라': 115,\n"," '시절': 116,\n"," '끝': 117,\n"," '스토리': 118,\n"," '개': 119,\n"," '해서': 120,\n"," '사랑': 121,\n"," '라면': 122,\n"," '처음': 123,\n"," '완전': 124,\n"," '감정': 125,\n"," '화': 126,\n"," '해야': 127,\n"," '작품': 128,\n"," '긴장감': 129,\n"," '랑': 130,\n"," '갈수록': 131,\n"," '더욱': 132,\n"," '잠': 133,\n"," '남': 134,\n"," '역시': 135,\n"," '씬': 136,\n"," '잊': 137,\n"," '용서': 138,\n"," '비판': 139,\n"," '시대': 140,\n"," '시간': 141,\n"," '죽': 142,\n"," '전': 143,\n"," '아름답': 144,\n"," '기억': 145,\n"," '여러': 146,\n"," '왔': 147,\n"," '일': 148,\n"," '알': 149,\n"," '봄': 150,\n"," '이정재': 151,\n"," '우정': 152,\n"," '해라': 153,\n"," '못': 154,\n"," '내내': 155,\n"," '샤': 156,\n"," '많이': 157,\n"," '그런가': 158,\n"," '흥미진진': 159,\n"," 'ㄷ': 160,\n"," 'ㅋㅋㅋ': 161,\n"," '티비': 162,\n"," '모르': 163,\n"," '인정': 164,\n"," '넘': 165,\n"," '내용': 166,\n"," '아요': 167,\n"," '한다': 168,\n"," '재': 169,\n"," '밋': 170,\n"," '음악': 171,\n"," '드라마': 172,\n"," '겠': 173,\n"," '가지': 174,\n"," '싫': 175,\n"," '어서': 176,\n"," '훌륭': 177,\n"," '인생': 178,\n"," '엔': 179,\n"," '첫': 180,\n"," '너무너무': 181,\n"," '보다': 182,\n"," '가을': 183,\n"," '연기자': 184,\n"," '요': 185,\n"," '했었': 186,\n"," '장르': 187,\n"," '디자인': 188,\n"," '학생': 189,\n"," '외국': 190,\n"," '디자이너': 191,\n"," '일군': 192,\n"," '통해': 193,\n"," '발전': 194,\n"," '산업': 195,\n"," '부러웠': 196,\n"," '어려운': 197,\n"," '열정': 198,\n"," '지킨': 199,\n"," '노라노': 200,\n"," '꿈': 201,\n"," '꾸': 202,\n"," '이뤄나갈': 203,\n"," '감사': 204,\n"," '폴리스': 205,\n"," '시리즈': 206,\n"," '뉴': 207,\n"," '버릴': 208,\n"," '께': 209,\n"," '쩔': 210,\n"," '구나': 211,\n"," '지루': 212,\n"," '할거': 213,\n"," '몰입': 214,\n"," '그래': 215,\n"," '안개': 216,\n"," '자욱': 217,\n"," '밤하늘': 218,\n"," '떠': 219,\n"," '초승달': 220,\n"," '입니다': 221,\n"," '전쟁': 222,\n"," '나요': 223,\n"," '빠': 224,\n"," '바보': 225,\n"," '병': 226,\n"," '쉰': 227,\n"," '나이': 228,\n"," '하지만': 229,\n"," '훗날': 230,\n"," '보면대': 231,\n"," '사': 232,\n"," '완벽': 233,\n"," '이해': 234,\n"," '고질라': 235,\n"," '니무': 236,\n"," '귀엽': 237,\n"," '능': 238,\n"," '오페라': 239,\n"," '극단': 240,\n"," '평갈': 241,\n"," '림': 242,\n"," '어쩔': 243,\n"," '반전': 244,\n"," '제': 245,\n"," '스릴감': 246,\n"," '전장': 247,\n"," '느끼': 248,\n"," '공포': 249,\n"," '생생': 250,\n"," '전해준다': 251,\n"," '고시': 252,\n"," '이터': 253,\n"," '소재': 254,\n"," '뿐': 255,\n"," '아무런': 256,\n"," '관련': 257,\n"," '단연': 258,\n"," '빠져드': 259,\n"," '밀회': 260,\n"," '화이팅': 261,\n"," '생각없이': 262,\n"," '상당': 263,\n"," '수작': 264,\n"," '일본': 265,\n"," '강렬': 266,\n"," '임팩트': 267,\n"," '일품': 268,\n"," '오랜만': 269,\n"," '제대로': 270,\n"," '범죄': 271,\n"," '스릴러': 272,\n"," '그런': 273,\n"," '해도': 274,\n"," '그저': 275,\n"," '한다는': 276,\n"," '마디': 277,\n"," '꺼내': 278,\n"," '벅차': 279,\n"," '밤': 280,\n"," '설치': 281,\n"," '커': 282,\n"," '징': 283,\n"," '텅': 284,\n"," '교복': 285,\n"," '션': 286,\n"," '자이': 287,\n"," '볼펜': 288,\n"," '자국': 289,\n"," '미처': 290,\n"," '전하': 291,\n"," '못한': 292,\n"," '형태': 293,\n"," '강압': 294,\n"," '세뇌': 295,\n"," '중세': 296,\n"," '이래': 297,\n"," '짜리': 298,\n"," '영상': 299,\n"," '존재': 300,\n"," '한다면': 301,\n"," '꼭': 302,\n"," '한번': 303,\n"," '슬픈': 304,\n"," '제니퍼코넬리': 305,\n"," '눈부신': 306,\n"," '아역': 307,\n"," '로버트드니로': 308,\n"," '장면': 309,\n"," '가슴': 310,\n"," '영원히': 311,\n"," '어떻': 312,\n"," '저런': 313,\n"," '짓': 314,\n"," 'ㅡㅡ': 315,\n"," '화나': 316,\n"," '더라': 317,\n"," '인간': 318,\n"," '잠재': 319,\n"," '악마': 320,\n"," '성': 321,\n"," '공간': 322,\n"," '존속': 323,\n"," '다큐': 324,\n"," '그것': 325,\n"," '엉뚱': 326,\n"," '광적': 327,\n"," '재현': 328,\n"," '삼': 329,\n"," '동안': 330,\n"," '쉬': 331,\n"," '틈틈이': 332,\n"," '줄여': 333,\n"," '여운': 334,\n"," '는다': 335,\n"," '실화': 336,\n"," '여서': 337,\n"," '충격': 338,\n"," '일어나': 339,\n"," '경각심': 340,\n"," '일깨워': 341,\n"," '존': 342,\n"," '그라': 343,\n"," '샴': 344,\n"," '번': 345,\n"," '쯤': 346,\n"," '가치': 347,\n"," '농아': 348,\n"," '아야': 349,\n"," '어렸': 350,\n"," '되게': 351,\n"," '이범수': 352,\n"," '쩜': 353,\n"," '매우': 354,\n"," '제발': 355,\n"," 'ㅠㅠ': 356,\n"," '어울린다': 357,\n"," '제이크': 358,\n"," '질렌할': 359,\n"," '넌': 360,\n"," '대체': 361,\n"," '냐': 362,\n"," '입가': 363,\n"," '미소': 364,\n"," '원표': 365,\n"," '조연': 366,\n"," '양': 367,\n"," '젤': 368,\n"," '는구만': 369,\n"," '마치': 370,\n"," '바다': 371,\n"," '아쿠아리움': 372,\n"," '들어간': 373,\n"," '어린': 374,\n"," '자녀': 375,\n"," '에게': 376,\n"," '강추': 377,\n"," '정의': 378,\n"," '세우': 379,\n"," '콜트': 380,\n"," '콜': 381,\n"," '텍': 382,\n"," '노동자': 383,\n"," '이야기': 384,\n"," '브라질': 385,\n"," '사라질': 386,\n"," '난': 387,\n"," '울렸': 388,\n"," '그리고': 389,\n"," '두': 390,\n"," '여배우': 391,\n"," '도법': 392,\n"," '멤버': 393,\n"," '모두': 394,\n"," '기대': 395,\n"," '됨': 396,\n"," '액션': 397,\n"," '겁나': 398,\n"," '던데': 399,\n"," '워낙에': 400,\n"," '격투': 401,\n"," '좋아해서': 402,\n"," '그냥': 403,\n"," '아무': 404,\n"," '없이': 405,\n"," '집': 406,\n"," '스마트': 407,\n"," '봐서': 408,\n"," '뭔': 409,\n"," '인지': 410,\n"," '암살': 411,\n"," '나온': 412,\n"," '길래': 413,\n"," '걍봄': 414,\n"," '하여튼': 415,\n"," 'ㅆ파르': 416,\n"," '북한': 417,\n"," '살만': 418,\n"," '목숨걸': 419,\n"," '대한민국': 420,\n"," '오': 421,\n"," '건데': 422,\n"," '그거': 423,\n"," '납득': 424,\n"," '시키': 425,\n"," '나불거려': 426,\n"," '종북': 427,\n"," '박평식': 428,\n"," '튼': 429,\n"," '대여': 430,\n"," '월이': 431,\n"," '비': 432,\n"," '내려야': 433,\n"," '그대': 434,\n"," '보이': 435,\n"," '시작': 436,\n"," '반가운': 437,\n"," '얼굴': 438,\n"," '여주인공': 439,\n"," '구': 440,\n"," '유쾌': 441,\n"," '요즘': 442,\n"," '아이': 443,\n"," '돌': 444,\n"," '먹': 445,\n"," '정도': 446,\n"," '봣는대요': 447,\n"," '받': 448,\n"," '잇': 449,\n"," '조': 450,\n"," '탱고': 451,\n"," '밀려': 452,\n"," '온다': 453,\n"," '평생': 454,\n"," '후회': 455,\n"," '뻔': 456,\n"," '따뜻': 457,\n"," '나왔': 458,\n"," '많': 459,\n"," '영상미': 460,\n"," '캐릭터': 461,\n"," '련결': 462,\n"," 'ㅠ': 463,\n"," '슬프': 464,\n"," '이제': 465,\n"," '잔잔': 466,\n"," '영순위': 467,\n"," '상당히': 468,\n"," '신동엽': 469,\n"," 'ㅋ': 470,\n"," '순간': 471,\n"," '캐치': 472,\n"," '탁': 473,\n"," '얄밉': 474,\n"," '긴': 475,\n"," '미워할': 476,\n"," '감탄': 477,\n"," '영': 478,\n"," '자랑': 479,\n"," '함': 480,\n"," '대박': 481,\n"," '텐데': 482,\n"," '왠': 483,\n"," '이동욱': 484,\n"," '전작': 485,\n"," '비해': 486,\n"," '떨어지': 487,\n"," '쓰레기': 488,\n"," '한국': 489,\n"," '점대': 490,\n"," '별': 491,\n"," '헐': 492,\n"," '니': 493,\n"," '다소': 494,\n"," '진부': 495,\n"," '어도': 496,\n"," '당시': 497,\n"," '눈물': 498,\n"," '사발': 499,\n"," '흘리': 500,\n"," '준': 501,\n"," 'pad': 1,\n"," 'unk': 0}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["이제 기존의 훈련 데이터에서 각 단어를 고유한 정수로 부여하는 작업을 진행해보겠습니다."],"metadata":{"id":"GGbCBl4m994H"}},{"cell_type":"code","source":["encoded = []\n","for line in tokenized: #입력 데이터에서 1줄씩 문장을 읽음\n","    temp = []\n","    for w in line: #각 줄에서 1개씩 글자를 읽음\n","      try:\n","        temp.append(word_to_index[w]) # 글자를 해당되는 정수로 변환\n","      except KeyError: # 단어 집합에 없는 단어일 경우 unk로 대체된다.\n","        temp.append(word_to_index['unk']) # unk의 인덱스로 변환\n","\n","    encoded.append(temp)\n","\n","print(encoded[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y24uKuqP-Jz3","executionInfo":{"status":"ok","timestamp":1735299012841,"user_tz":-540,"elapsed":428,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"069572a1-f050-4952-fdd1-fa12f30478ea"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[[79, 27, 9, 4, 50, 42, 80, 16, 28, 29], [188, 5, 81, 189, 190, 191, 43, 192, 113, 5, 193, 194, 24, 114, 195, 196, 13, 51, 82, 115, 30, 43, 197, 116, 117, 31, 198, 5, 199, 200, 17, 113, 7, 68, 52, 17, 44, 201, 5, 202, 4, 203, 14, 7, 83, 32, 204, 84], [205, 118, 206, 53, 207, 31, 208, 209, 54, 10, 25, 11], [45, 33, 119, 210, 211, 212, 213, 69, 46, 34, 13, 214, 120, 15, 2, 215, 70, 8, 33, 3, 35], [216, 217, 218, 219, 7, 220, 17, 3], [121, 5, 24, 36, 44, 122, 123, 53, 117, 31, 85, 5, 14, 7, 3], [124, 37, 221, 42, 80, 37], [119, 222, 55, 223, 55, 86, 224, 38, 9, 4, 47, 25], [56], [225, 87, 88, 226, 227, 57, 89]]\n"]}]},{"cell_type":"markdown","source":["#### 길이가 다른 문장들을 모두 동일한 길이로 바꿔주는 패딩(padding)\n","\n","- 이제 길이가 다른 리뷰들을 모두 동일한 길이로 바꿔주는 패딩 작업을 진행해보겠습니다.\n","- 앞서 단어 집합에 패딩을 위한 토큰인 'pad'를 추가했었습니다.\n","- 패딩 작업은 정해준 길이로 모든 샘플들의 길이를 맞춰주되, 길이가 정해준 길이보다 짧은 샘플들에는 'pad' 토큰을 추가하여 길이를 맞춰주는 작업입니다."],"metadata":{"id":"9CI-uEE0-PZu"}},{"cell_type":"code","source":["max_len = max(len(l) for l in encoded)\n","print('리뷰의 최대 길이 : %d' % max_len)\n","print('리뷰의 최소 길이 : %d' % min(len(l) for l in encoded))\n","print('리뷰의 평균 길이 : %f' % (sum(map(len, encoded))/len(encoded)))\n","plt.hist([len(s) for s in encoded], bins=50)\n","plt.xlabel('length of sample')\n","plt.ylabel('number of sample')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"KHYNRnoP-bEP","executionInfo":{"status":"ok","timestamp":1735299022405,"user_tz":-540,"elapsed":464,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"87920bb0-9aba-410c-8765-836d313e60bc"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["리뷰의 최대 길이 : 62\n","리뷰의 최소 길이 : 1\n","리뷰의 평균 길이 : 13.900000\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["가장 길이가 긴 리뷰의 길이는 63입니다. 모든 리뷰의 길이를 63으로 통일시켜주겠습니다."],"metadata":{"id":"c2mFJp2G-e4S"}},{"cell_type":"code","source":["for line in encoded:\n","    if len(line) < max_len: # 현재 샘플이 정해준 길이보다 짧으면\n","        line += [word_to_index['pad']] * (max_len - len(line)) # 나머지는 전부 'pad' 토큰으로 채운다."],"metadata":{"id":"wWLx11ex-fgu","executionInfo":{"status":"ok","timestamp":1735299026241,"user_tz":-540,"elapsed":2,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["print(encoded[:3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5eM5S0_O-iAz","executionInfo":{"status":"ok","timestamp":1735299027684,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"83d350b7-9293-42e5-a744-d50cd1a2081a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[[79, 27, 9, 4, 50, 42, 80, 16, 28, 29, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [188, 5, 81, 189, 190, 191, 43, 192, 113, 5, 193, 194, 24, 114, 195, 196, 13, 51, 82, 115, 30, 43, 197, 116, 117, 31, 198, 5, 199, 200, 17, 113, 7, 68, 52, 17, 44, 201, 5, 202, 4, 203, 14, 7, 83, 32, 204, 84, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [205, 118, 206, 53, 207, 31, 208, 209, 54, 10, 25, 11, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"]}]},{"cell_type":"markdown","source":["- 이제 단어들을 고유한 정수로 맵핑하였으니, 각 정수를 수치화된 벡터로 바꾸는 작업이 필요합니다. 즉, Step 2인 임베딩이 필요합니다.\n"],"metadata":{"id":"Be9e2tPc-l_v"}},{"cell_type":"markdown","source":["## (Step 2) 임베딩 (Embedding)\n","\n","- 문서를 벡터화 하는 방법에 대해서 학습합니다.\n","- 각 정수를 벡터로 바꾸는 과정은 크게 원-핫 인코딩과 **임베딩**이 있는데, 주로 임베딩이 사용됩니다.\n","  + 원-핫 인코딩(One-hot encoding)\n","  + **임베딩(Embedding)**"],"metadata":{"id":"MoBDBd1tBBYn"}},{"cell_type":"markdown","source":["###  원-핫 인코딩(One-hot encoding)이란\n","\n","원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 단어의 벡터 표현 방식입니다. 이렇게 표현된 벡터를 원-핫 벡터(One-hot vector)라고 합니다.\n","\n","원-핫 인코딩을 두 가지 과정으로 정리해보겠습니다.\n","- (1) 각 단어에 고유한 인덱스를 부여합니다. (정수 인코딩)\n","- (2) 표현하고 싶은 단어의 인덱스의 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여합니다.\n","\n","<img src='https://drive.google.com/uc?export=download&id=1dqHgahjYHAZnhg2tb1ij8_17WUHtBaOz' width=\"\" height =\"\" /><br>\n","\n","이해를 돕기 위해서 한국어 문장을 예제로 원-핫 벡터를 만들어보겠습니다.\n","우선, 한국어 자연어 처리를 위해 코엔엘파이 패키지를 설치합니다."],"metadata":{"id":"X3We66iYCFnQ"}},{"cell_type":"code","source":["!pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6AbTquaxC0dQ","executionInfo":{"status":"ok","timestamp":1715694051657,"user_tz":-540,"elapsed":8121,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"458ee482-beb0-4448-8806-700c5d228214"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.0)\n"]}]},{"cell_type":"markdown","source":["**문장 : 나는 자연어 처리를 배운다**\n","\n","위 문장에 대해서 원-핫 인코딩을 진행하는 코드는 아래와 같습니다."],"metadata":{"id":"YFJjEuiTCzX2"}},{"cell_type":"code","source":["from konlpy.tag import Okt\n","okt = Okt()\n","token = okt.morphs(\"나는 자연어 처리를 배운다\")\n","print(token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3T_6P0Y4C6CB","executionInfo":{"status":"ok","timestamp":1715694091778,"user_tz":-540,"elapsed":25420,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"dc444c3a-c923-4407-f42b-86162ce17e35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['나', '는', '자연어', '처리', '를', '배운다']\n"]}]},{"cell_type":"markdown","source":["코엔엘파이의 Okt 형태소 분석기를 통해서 우선 문장에 대해서 토큰화를 수행하였습니다."],"metadata":{"id":"FlONqaiOC97K"}},{"cell_type":"code","source":["word2index = {}\n","for voca in token:\n","     if voca not in word2index.keys():\n","       word2index[voca] = len(word2index)\n","\n","print(word2index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VuLOHsEHC9dt","executionInfo":{"status":"ok","timestamp":1715694103900,"user_tz":-540,"elapsed":287,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"c791ccd4-87b0-47e5-e51c-a32e985f70a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"]}]},{"cell_type":"markdown","source":["각 토큰에 대해서 고유한 인덱스(index)를 부여하였습니다. 지금은 문장이 짧기 때문에 각 단어의 빈도수를 고려하지 않지만, 빈도수 순대로 단어를 정렬하여 고유한 인덱스를 부여하는 작업이 사용되기도 합니다."],"metadata":{"id":"wRueuohFDCjw"}},{"cell_type":"code","source":["def one_hot_encoding(word, word2index):\n","    one_hot_vector = [0]*(len(word2index))\n","    index = word2index[word]\n","    one_hot_vector[index] = 1\n","    return one_hot_vector"],"metadata":{"id":"vRvZgsdGDFtA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["토큰을 입력하면 해당 토큰에 대한 원-핫 벡터를 만들어내는 함수를 만들었습니다."],"metadata":{"id":"qQBkzntHDK09"}},{"cell_type":"code","source":["one_hot_encoding(\"자연어\",word2index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGbH1fRgDLqV","executionInfo":{"status":"ok","timestamp":1715696786795,"user_tz":-540,"elapsed":367,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"d61312a5-1a81-4e53-fd70-456d28e1be52"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 0, 1, 0, 0, 0]"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["해당 함수에 '자연어'라는 토큰을 입력으로 넣어봤더니 [0, 0, 1, 0, 0, 0]라는 벡터가 나왔습니다. 자연어는 단어 집합에서 인덱스가 2이므로, 자연어를 표현하는 원-핫 벡터는 인덱스 2의 값이 1이며, 나머지 값은 0인 벡터가 나옵니다."],"metadata":{"id":"84btSnWPDNA-"}},{"cell_type":"markdown","source":["- 이러한 표현 방식은 단어의 개수가 늘어날 수록, 벡터를 저장하기 위해 필요한 공간이 계속 늘어난다는 단점이 있습니다. 다른 말로는 벡터의 차원이 계속 늘어난다고도 표현합니다. 원 핫 벡터는 단어 집합의 크기가 곧 벡터의 차원 수가 됩니다.\n","\n","- 또한 원-핫 벡터는 단어의 유사도를 표현하지 못한다는 단점이 있습니다.\n","  + 예를 들어서 늑대, 호랑이, 강아지, 고양이라는 4개의 단어에 대해서 원-핫 인코딩을 해서 각각, [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]이라는 원-핫 벡터를 부여받았다고 합시다.\n","  + 이 때 원-핫 벡터로는 강아지와 늑대가 유사하고, 호랑이와 고양이가 유사하다는 것을 표현할 수가 없습니다.\n","\n","- 이러한 한계를 극복하기 위한 것이 워드 임베딩\n","\n","<img src='https://drive.google.com/uc?export=download&id=1wFR-_7HBvJlzA4a55yZ7BwamezU4gKbp' width=\"\" height =\"\" /><br>"],"metadata":{"id":"a867enYBDRV0"}},{"cell_type":"markdown","source":["### 임베딩(Embedding)\n","\n","파이토치에서는 임베딩 벡터를 사용하는 방법이 크게 두 가지가 있습니다.\n","\n","- `nn.embedding()` : 임베딩 층(embedding layer)을 만들어 훈련 데이터로부터 처음부터 임베딩 벡터를 학습.\n","  + 단어를 랜덤한 값을 가지는 밀집 벡터로 변환한 뒤에, 인공 신경망의 가중치를 학습하는 것과 같은 방식으로 단어 벡터를 학습\n","- 사전에 훈련된 임베딩 벡터(pre-trained word embedding)들을 가져와 사용하는 방법\n","  + `Word2Vec`, `Glove` 등.\n"],"metadata":{"id":"3q1W1RxKE7Vt"}},{"cell_type":"markdown","source":["#### (a) 파이토치(PyTorch)의 `nn.Embedding()`"],"metadata":{"id":"RRrFv6gLOWvY"}},{"cell_type":"code","source":["train_data = 'you need to know how to code'\n","\n","# 중복을 제거한 단어들의 집합인 단어 집합 생성.\n","word_set = set(train_data.split())\n","\n","# 단어 집합의 각 단어에 고유한 정수 맵핑.\n","vocab = {tkn: i+2 for i, tkn in enumerate(word_set)}\n","vocab['<unk>'] = 0\n","vocab['<pad>'] = 1\n"],"metadata":{"id":"O-injeTbPZPG","executionInfo":{"status":"ok","timestamp":1735300444902,"user_tz":-540,"elapsed":399,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["이제 `nn.Embedding()`을 사용하여 학습가능한 임베딩 테이블을 만듭니다."],"metadata":{"id":"fk-o5b91PaTa"}},{"cell_type":"code","source":["import torch.nn as nn\n","embedding_layer = nn.Embedding(num_embeddings=len(vocab),\n","                               embedding_dim=3,\n","                               padding_idx=1)"],"metadata":{"id":"94Ytm46BPb2V","executionInfo":{"status":"ok","timestamp":1735300449282,"user_tz":-540,"elapsed":375,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["`nn.Embedding`은 크게 두 가지 인자를 받는데 각각 `num_embeddings`과 `embedding_dim`입니다.\n","\n","- `num_embeddings` : 임베딩을 할 단어들의 개수. 다시 말해 단어 집합의 크기입니다.\n","- `embedding_dim` : 임베딩 할 벡터의 차원입니다. 사용자가 정해주는 하이퍼파라미터입니다.\n","- `padding_idx` : 선택적으로 사용하는 인자입니다. 패딩을 위한 토큰의 인덱스를 알려줍니다."],"metadata":{"id":"mqEyXq46PdDG"}},{"cell_type":"code","source":["print(embedding_layer.weight)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwkAZMcPPnlJ","executionInfo":{"status":"ok","timestamp":1735300455075,"user_tz":-540,"elapsed":420,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"bdc57be6-1b44-4448-d11b-47cf00b0364e"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[ 0.3682, -0.6995, -1.2260],\n","        [ 0.0000,  0.0000,  0.0000],\n","        [ 0.8029, -0.0241,  0.6877],\n","        [-0.7583, -0.0071,  0.1141],\n","        [ 0.4690, -1.6141,  0.2748],\n","        [ 0.2197,  1.1585,  0.4956],\n","        [-2.1068, -0.5348, -0.5965],\n","        [ 0.2858, -1.5039, -1.1757]], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["#### (b) 사전 훈련된 워드 임베딩(Pre-trained Word Embedding)\n","\n","임베딩 벡터를 얻기 위해서 파이토치의 `nn.Embedding()`을 사용하기도 하지만, 때로는 이미 훈련되어져 있는 워드 임베딩을 불러서 이를 임베딩 벡터로 사용하기도 합니다. 훈련 데이터가 부족한 상황이라면 모델에 파이토치의 `nn.Embedding()`을 사용하는 것보다 다른 텍스트 데이터로 사전 훈련되어 있는 임베딩 벡터를 불러오는 것이 나은 선택일 수 있습니다.\n","\n","훈련 데이터가 적다면 파이토치의 `nn.Embedding()`으로 해당 문제에 충분히 특화된 임베딩 벡터를 만들어내는 것이 쉽지 않습니다. 이 경우, 해당 문제에 특화된 것은 아니지만 보다 일반적이고 보다 많은 훈련 데이터로 이미 `Word2Vec`이나 `GloVe` 등으로 학습되어져 있는 임베딩 벡터들을 사용하는 것이 성능의 개선을 가져올 수 있습니다."],"metadata":{"id":"mUvB-3cIRmkk"}},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XoA5jxeHR-m9","executionInfo":{"status":"ok","timestamp":1735300478828,"user_tz":-540,"elapsed":3528,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"b98fcfd9-a69f-4737-80d2-f36d9d12361e"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.1.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"]}]},{"cell_type":"markdown","source":["### 4-1) 사전 훈련된 임베딩을 사용하지 않는 경우"],"metadata":{"id":"aU9udj2FR5sx"}},{"cell_type":"code","source":["import numpy as np\n","from collections import Counter\n","import gensim"],"metadata":{"id":"dgXYBKNpR9Wy","executionInfo":{"status":"ok","timestamp":1735300484179,"user_tz":-540,"elapsed":3313,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["문장의 긍, 부정을 판단하는 감성 분류 모델을 만들어봅시다. 문장과 레이블 데이터를 만들었습니다. 긍정인 문장은 레이블 1, 부정인 문장은 레이블이 0입니다."],"metadata":{"id":"XRDsUga9SCHR"}},{"cell_type":"code","source":["sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n","y_train = [1, 0, 0, 1, 1, 0, 1]"],"metadata":{"id":"ECYfasSnSCqR","executionInfo":{"status":"ok","timestamp":1735300486939,"user_tz":-540,"elapsed":427,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["각 샘플에 대해서 단어 토큰화를 수행합니다."],"metadata":{"id":"1fbCateTSDbC"}},{"cell_type":"code","source":["tokenized_sentences = [sent.split() for sent in sentences]\n","print('단어 토큰화 된 결과 :', tokenized_sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jzclb6T1SGwt","executionInfo":{"status":"ok","timestamp":1735300489502,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"f62ebe93-dd65-43bb-b95f-e930f54511de"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 토큰화 된 결과 : [['nice', 'great', 'best', 'amazing'], ['stop', 'lies'], ['pitiful', 'nerd'], ['excellent', 'work'], ['supreme', 'quality'], ['bad'], ['highly', 'respectable']]\n"]}]},{"cell_type":"markdown","source":["토큰화 된 결과를 바탕으로 단어 집합을 만들어봅시다. 우선 Counter() 모듈을 이용하여 각 단어의 등장 빈도수를 기록합니다."],"metadata":{"id":"9UdgTs1JSKT9"}},{"cell_type":"code","source":["word_list = []\n","for sent in tokenized_sentences:\n","    for word in sent:\n","      word_list.append(word)\n","\n","word_counts = Counter(word_list)\n","print('총 단어수 :', len(word_counts))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ORhz1cvSLr1","executionInfo":{"status":"ok","timestamp":1735300492162,"user_tz":-540,"elapsed":474,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"fbbd7e84-5400-4fe0-cdb6-54d6c59822f6"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["총 단어수 : 15\n"]}]},{"cell_type":"markdown","source":["현재 존재하는 총 단어의 수는 15개입니다. 이 단어들을 등장 빈도가 높은 순서부터 정렬합니다."],"metadata":{"id":"1WN6hC_dSPmK"}},{"cell_type":"code","source":["# 등장 빈도순으로 정렬\n","vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3cRh2iGSRCR","executionInfo":{"status":"ok","timestamp":1735300495164,"user_tz":-540,"elapsed":448,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"c7c8709a-5f2d-45c0-e2b1-0cae821e1aeb"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["['nice', 'great', 'best', 'amazing', 'stop', 'lies', 'pitiful', 'nerd', 'excellent', 'work', 'supreme', 'quality', 'bad', 'highly', 'respectable']\n"]}]},{"cell_type":"markdown","source":["nice가 등장 빈도수로 가장 높은 단어이고, 그 다음은 great, 그 다음은 best로 등장 빈도가 높은 순서대로 단어가 정렬된 상태입니다. 이제 이로부터 단어 집합을 완성해봅시다. 0번은 패딩 토큰을 위한 용도로 사용하고, 1번은 단어 집합에 없는 단어가 등장하는 OOV(Out-Of-Vocabulary) 문제가 발생하면 사용하는 용도로 각각 할당합니다."],"metadata":{"id":"vYLcMbvnSSYt"}},{"cell_type":"code","source":["word_to_index = {}\n","word_to_index['<PAD>'] = 0\n","word_to_index['<UNK>'] = 1\n","\n","for index, word in enumerate(vocab) :\n","  word_to_index[word] = index + 2\n","\n","vocab_size = len(word_to_index)\n","print('패딩 토큰, UNK 토큰을 고려한 단어 집합의 크기 :', vocab_size)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3KnNLkmSUKf","executionInfo":{"status":"ok","timestamp":1735300497967,"user_tz":-540,"elapsed":496,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"7f37ff2b-957c-46eb-c1a6-58572fb58cce"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["패딩 토큰, UNK 토큰을 고려한 단어 집합의 크기 : 17\n"]}]},{"cell_type":"markdown","source":["단어 집합의 크기는 17입니다. 출력 결과는 다음과 같습니다."],"metadata":{"id":"a_eUNNZWSWDT"}},{"cell_type":"code","source":["print(word_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--f8aJeMSW7n","executionInfo":{"status":"ok","timestamp":1735300500647,"user_tz":-540,"elapsed":721,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"6e0bd34a-e741-4bca-82b0-fe80e4edd01e"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["{'<PAD>': 0, '<UNK>': 1, 'nice': 2, 'great': 3, 'best': 4, 'amazing': 5, 'stop': 6, 'lies': 7, 'pitiful': 8, 'nerd': 9, 'excellent': 10, 'work': 11, 'supreme': 12, 'quality': 13, 'bad': 14, 'highly': 15, 'respectable': 16}\n"]}]},{"cell_type":"markdown","source":["단어 집합을 이용하여 정수 인코딩을 진행합니다. 단어 집합에 없는 단어가 등장할 경우에는 정수 1이 할당되지만 이번 실습에서는 학습 데이터에 단어 집합에 없는 단어가 존재하지 않으므로 해당되지 않습니다."],"metadata":{"id":"YNezHpnISYNb"}},{"cell_type":"code","source":["def texts_to_sequences(tokenized_X_data, word_to_index):\n","  encoded_X_data = []\n","  for sent in tokenized_X_data:\n","    index_sequences = []\n","    for word in sent:\n","      try:\n","          index_sequences.append(word_to_index[word])\n","      except KeyError:\n","          index_sequences.append(word_to_index['<UNK>'])\n","    encoded_X_data.append(index_sequences)\n","  return encoded_X_data\n","\n","X_encoded = texts_to_sequences(tokenized_sentences, word_to_index)\n","print(X_encoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkR3i0jZSZhj","executionInfo":{"status":"ok","timestamp":1735300503815,"user_tz":-540,"elapsed":542,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"992732b1-14b8-4e3a-f4ff-572b90a1a9c0"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2, 3, 4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14], [15, 16]]\n"]}]},{"cell_type":"markdown","source":["현재 데이터의 최대 길이를 측정하고, 해당 길이로 패딩을 진행합니다."],"metadata":{"id":"hO7oU-AEShZI"}},{"cell_type":"code","source":["max_len = max(len(l) for l in X_encoded)\n","print('최대 길이 :',max_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XPxJErsGSgWS","executionInfo":{"status":"ok","timestamp":1735300507063,"user_tz":-540,"elapsed":384,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"e2a574c4-42cf-494b-b6ba-647a54a79d3d"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["최대 길이 : 4\n"]}]},{"cell_type":"code","source":["def pad_sequences(sentences, max_len):\n","  features = np.zeros((len(sentences), max_len), dtype=int)\n","  for index, sentence in enumerate(sentences):\n","    if len(sentence) != 0:\n","      features[index, :len(sentence)] = np.array(sentence)[:max_len]\n","  return features\n","\n","X_train = pad_sequences(X_encoded, max_len=max_len)\n","y_train = np.array(y_train)\n","print('패딩 결과 :')\n","print(X_train)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YumQWGjISmKF","executionInfo":{"status":"ok","timestamp":1735300509974,"user_tz":-540,"elapsed":475,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"8a10878f-8b9e-46e8-810f-e4897dbfaaaf"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["패딩 결과 :\n","[[ 2  3  4  5]\n"," [ 6  7  0  0]\n"," [ 8  9  0  0]\n"," [10 11  0  0]\n"," [12 13  0  0]\n"," [14  0  0  0]\n"," [15 16  0  0]]\n"]}]},{"cell_type":"markdown","source":["모든 데이터의 길이가 4로 변환된 것을 확인하였습니다. 이제 `nn.Embedding()`를 이용하여 모델을 설계합니다."],"metadata":{"id":"-L3_Hm4PSoRN"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader, TensorDataset\n"],"metadata":{"id":"WhtxZLPKSp2u","executionInfo":{"status":"ok","timestamp":1735300513673,"user_tz":-540,"elapsed":797,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["class SimpleModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim):\n","        super(SimpleModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(embedding_dim * max_len, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        # embedded.shape == (배치 크기, 문장의 길이, 임베딩 벡터의 차원)\n","        embedded = self.embedding(x)\n","\n","        # flattend.shape == (배치 크기, 문장의 길이 × 임베딩 벡터의 차원)\n","        flattened = self.flatten(embedded)\n","\n","        # output.shape == (배치 크기, 1)\n","        output = self.fc(flattened)\n","        return self.sigmoid(output)\n"],"metadata":{"id":"YYAPiGIvSqlF","executionInfo":{"status":"ok","timestamp":1735300516003,"user_tz":-540,"elapsed":433,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["모델 객체를 선언합니다. 임베딩 벡터의 크기는 100으로 정했습니다."],"metadata":{"id":"5lxsCD1aSrUN"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","embedding_dim = 100\n","simple_model = SimpleModel(vocab_size, embedding_dim).to(device)\n"],"metadata":{"id":"4GvcUQIETGN1","executionInfo":{"status":"ok","timestamp":1735300519273,"user_tz":-540,"elapsed":877,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["출력층에 로지스틱 회귀를 이용한 이진 분류 문제를 푸는 모델이므로 손실 함수로는 바이너리 크로스엔트로피 함수에 해당하는 `nn.BCELoss()`를 사용합니다."],"metadata":{"id":"AYCFPg88Szcj"}},{"cell_type":"code","source":["criterion = nn.BCELoss()\n","optimizer = Adam(simple_model.parameters())\n"],"metadata":{"id":"mth8jvM5S04O","executionInfo":{"status":"ok","timestamp":1735300533258,"user_tz":-540,"elapsed":12015,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["데이터를 배치 크기 2로 설정한 데이터로더로 변환합니다."],"metadata":{"id":"kz7H3Z-eS17k"}},{"cell_type":"code","source":["train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32))\n","train_dataloader = DataLoader(train_dataset, batch_size=2)\n"],"metadata":{"id":"81hLTKWSS2f8","executionInfo":{"status":"ok","timestamp":1735300533258,"user_tz":-540,"elapsed":4,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["데이터가 7개였으므로 배치 크기 2로 묶으면 총 묶음은 4개(2개, 2개, 2개, 1개)가 됩니다."],"metadata":{"id":"WdOHCKS3S3OI"}},{"cell_type":"code","source":["print(len(train_dataloader))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DsficQvES4cU","executionInfo":{"status":"ok","timestamp":1735300533258,"user_tz":-540,"elapsed":4,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"60fe3ee0-361e-4b47-f25d-1c600ddaec9a"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n"]}]},{"cell_type":"markdown","source":["총 10번 학습합니다."],"metadata":{"id":"UCC8KPWZS5s4"}},{"cell_type":"code","source":["for epoch in range(10):\n","    for inputs, targets in train_dataloader:\n","        # inputs.shape == (배치 크기, 문장 길이)\n","        # targets.shape == (배치 크기)\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # outputs.shape == (배치 크기)\n","        outputs = simple_model(inputs).view(-1)\n","\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lFshY0BtS6ln","executionInfo":{"status":"ok","timestamp":1735300536568,"user_tz":-540,"elapsed":421,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"4a5b883b-ecde-4fca-9efb-6bdd10cfee67"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.8481619358062744\n","Epoch 2, Loss: 0.5882623195648193\n","Epoch 3, Loss: 0.400343656539917\n","Epoch 4, Loss: 0.28641393780708313\n","Epoch 5, Loss: 0.22234389185905457\n","Epoch 6, Loss: 0.1870885193347931\n","Epoch 7, Loss: 0.1671459972858429\n","Epoch 8, Loss: 0.15437524020671844\n","Epoch 9, Loss: 0.14393948018550873\n","Epoch 10, Loss: 0.1333150714635849\n"]}]},{"cell_type":"markdown","source":["### 4-2) 사전 훈련된 임베딩을 사용하는 경우"],"metadata":{"id":"N0A6Zp5LR7St"}},{"cell_type":"markdown","source":["구글에서 사전 학습시킨 Word2Vec 모델을 사용하여 문제를 풀어봅시다. 우선 구글에서 사전 학습시킨 Word2Vec 모델을 다운로드 합니다."],"metadata":{"id":"sbBR5zafPmtb"}},{"cell_type":"code","source":["!pip install gdown\n","!gdown https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8uzgB8UTSom","executionInfo":{"status":"ok","timestamp":1735300779165,"user_tz":-540,"elapsed":53741,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"f0405bac-3bff-4aed-d85b-305036026f3e"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j\n","From (redirected): https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j&confirm=t&uuid=e3e728c4-b3d4-4798-931e-20fc75f32c0a\n","To: /content/Mecab-ko-for-Google-Colab/GoogleNews-vectors-negative300.bin.gz\n","100% 1.65G/1.65G [00:45<00:00, 36.3MB/s]\n"]}]},{"cell_type":"markdown","source":["머신 러닝 라이브러리 gensim을 이용하여 해당 모델을 다운로드합니다."],"metadata":{"id":"mHKPpvWNTU87"}},{"cell_type":"code","source":["# 구글의 사전 훈련된 Word2vec 모델을 로드합니다.\n","word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"],"metadata":{"id":"qOwEpHC0TUVs","executionInfo":{"status":"ok","timestamp":1735300971328,"user_tz":-540,"elapsed":68833,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["위 모델은 각 벡터가 300차원으로 구성되어져 있습니다. 풀고자 하는 문제의 단어 집합 크기의 행과 300개의 열을 가지는 행렬 생성합니다. 이 행렬의 값은 전부 0으로 채웁니다. 이 행렬에 사전 훈련된 임베딩 값을 넣어줄 것입니다."],"metadata":{"id":"9ljb5H2ETWTU"}},{"cell_type":"code","source":["embedding_matrix = np.zeros((vocab_size, 300))\n","print('임베딩 행렬의 크기 :', embedding_matrix.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vthhd5dKTYW4","executionInfo":{"status":"ok","timestamp":1735301030718,"user_tz":-540,"elapsed":422,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"e82f7d35-225e-4baa-9b38-b547254d514f"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["임베딩 행렬의 크기 : (17, 300)\n"]}]},{"cell_type":"markdown","source":["word2vec_model에서 특정 단어를 입력하면 해당 단어의 임베딩 벡터를 리턴받을텐데, 만약 word2vec_model에 특정 단어의 임베딩 벡터가 없다면 None을 리턴하도록 하는 함수 `get_vector()`를 구현합니다."],"metadata":{"id":"Ohmg-iHLTSDR"}},{"cell_type":"code","source":["def get_vector(word):\n","    if word in word2vec_model:\n","        return word2vec_model[word]\n","    else:\n","        return None\n"],"metadata":{"id":"dQfmfjFZTa-L","executionInfo":{"status":"ok","timestamp":1735301038442,"user_tz":-540,"elapsed":375,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["단어 집합으로부터 단어를 1개씩 호출하여 word2vec_model에 해당 단어의 임베딩 벡터값이 존재하는지 확인합니다. 만약 None이 아니라면 존재한다는 의미이므로 임베딩 행렬에 해당 단어의 인덱스 위치의 행에 임베딩 벡터의 값을 저장합니다."],"metadata":{"id":"n6jQf-GyTcRj"}},{"cell_type":"code","source":["# <PAD>를 위한 0번과 <UNK>를 위한 1번은 실제 단어가 아니므로 맵핑에서 제외\n","for word, i in word_to_index.items():\n","    if i > 2:\n","      temp = get_vector(word)\n","      if temp is not None:\n","          embedding_matrix[i] = temp\n"],"metadata":{"id":"lMfvTnPqTc1D","executionInfo":{"status":"ok","timestamp":1735301040374,"user_tz":-540,"elapsed":2,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["현재 풀고자하는 문제의 17개의 단어와 맵핑되는 임베딩 행렬이 완성됩니다. 0번 단어는 패딩을 위한 용도이므로 사전 훈련된 임베딩 벡터값이 불필요합니다. 이에 따라 초기값인 0벡터로 초기화가 되어져 있습니다. embedding_matrix의 0번 위치의 벡터를 출력해봅시다."],"metadata":{"id":"vAxt0KakTdlN"}},{"cell_type":"code","source":["# <PAD>나 <UNK>의 경우는 사전 훈련된 임베딩이 들어가지 않아서 0벡터임\n","print(embedding_matrix[0])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-Bb9a-2Te40","executionInfo":{"status":"ok","timestamp":1735301044949,"user_tz":-540,"elapsed":414,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"3dab430c-7469-41df-ef72-812f5f776a3c"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}]},{"cell_type":"markdown","source":["0이 300개 채워진 벡터임을 확인하였습니다. 이제 다른 단어들도 제대로 맵핑이 됐는지 확인해볼까요? 기존의 단어 집합에서 단어 'great'가 정수로 몇 번인지 확인합니다."],"metadata":{"id":"f6TM4JwsTgBr"}},{"cell_type":"code","source":["word_to_index['great']\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0xsI3XHThXn","executionInfo":{"status":"ok","timestamp":1735301047775,"user_tz":-540,"elapsed":437,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"1fe1242b-21d9-4509-bb87-422b32cf90f5"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["3번 임을 확인했습니다. 이에 따라서 사전 훈련된 word2vec_model에서의 'great' 벡터와 현재 사전 훈련된 임베딩 벡터가 맵핑된 embedding_matrix의 3번 벡터가 동일한지 확인합니다."],"metadata":{"id":"LuatEhBXTiJU"}},{"cell_type":"code","source":["# word2vec_model에서 'great'의 임베딩 벡터\n","# embedding_matrix[3]이 일치하는지 체크\n","np.all(word2vec_model['great'] == embedding_matrix[3])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UHO37tUjTi4o","executionInfo":{"status":"ok","timestamp":1735301050206,"user_tz":-540,"elapsed":400,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"e8ef1451-b2d9-4d3e-c3ce-9d2775b958ba"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["동일한 것을 확인하였습니다. 이는 현재 3번 위치에 단어 'great' 벡터가 정상적으로 할당되었음을 의미합니다. 이제 사전 훈련된 임베딩을 이용한 모델을 구현합니다."],"metadata":{"id":"QwiTCvrqTjrE"}},{"cell_type":"code","source":["class PretrainedEmbeddingModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim):\n","        super(PretrainedEmbeddingModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding.weight.requires_grad = True\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(embedding_dim * max_len, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x)\n","        flattened = self.flatten(embedded)\n","        output = self.fc(flattened)\n","        return self.sigmoid(output)\n"],"metadata":{"id":"Pe-Zc2Z5TkrJ","executionInfo":{"status":"ok","timestamp":1735301052843,"user_tz":-540,"elapsed":5,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["모델 객체를 선언합니다. 이때 임베딩 벡터의 크기는 embedding_matrix에서 이미 정해진 임베딩 벡터의 차원인 300으로 해야만 합니다."],"metadata":{"id":"N_SUrCY5TlbI"}},{"cell_type":"code","source":["pretraiend_embedding_model = PretrainedEmbeddingModel(vocab_size, 300).to(device)\n"],"metadata":{"id":"7DziCXs8TmVg","executionInfo":{"status":"ok","timestamp":1735301056461,"user_tz":-540,"elapsed":433,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":["출력층에 로지스틱 회귀를 이용한 이진 분류 문제를 푸는 모델이므로 손실 함수로는 바이너리 크로스엔트로피 함수에 해당하는 nn.BCELoss()를 사용합니다."],"metadata":{"id":"ZxTGgm2dTnEL"}},{"cell_type":"code","source":["criterion = nn.BCELoss()\n","optimizer = Adam(pretraiend_embedding_model.parameters())"],"metadata":{"id":"3xBKF4YKToP9","executionInfo":{"status":"ok","timestamp":1735301058380,"user_tz":-540,"elapsed":2,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["데이터를 배치 크기 2로 설정한 데이터로더로 변환합니다."],"metadata":{"id":"_qME3PUFTp85"}},{"cell_type":"code","source":["train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32))\n","train_dataloader = DataLoader(train_dataset, batch_size=2)\n"],"metadata":{"id":"g0q-SAC1TriR","executionInfo":{"status":"ok","timestamp":1735301061276,"user_tz":-540,"elapsed":2,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":["데이터가 7개였으므로 배치 크기 2로 묶으면 총 묶음은 4개(2개, 2개, 2개, 1개)가 됩니다."],"metadata":{"id":"Jc5QcBJVTqwU"}},{"cell_type":"code","source":["print(len(train_dataloader))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVS8EGSuTu2-","executionInfo":{"status":"ok","timestamp":1735301063788,"user_tz":-540,"elapsed":771,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"d3ee60e6-be39-4540-d018-917e361e6888"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n"]}]},{"cell_type":"markdown","source":["총 10번 학습합니다."],"metadata":{"id":"2NqBOThQTtK2"}},{"cell_type":"code","source":["for epoch in range(10):\n","    for inputs, targets in train_dataloader:\n","        # inputs.shape == (배치 크기, 문장 길이)\n","        # targets.shape == (배치 크기)\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # outputs.shape == (배치 크기)\n","        outputs = pretraiend_embedding_model(inputs).view(-1)\n","\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24d9VC3NTuAJ","executionInfo":{"status":"ok","timestamp":1735301067620,"user_tz":-540,"elapsed":426,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"ef8c3f4a-1eaa-494c-804b-94d95073bcc6"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.7208788990974426\n","Epoch 2, Loss: 0.6546679139137268\n","Epoch 3, Loss: 0.5890753269195557\n","Epoch 4, Loss: 0.5275224447250366\n","Epoch 5, Loss: 0.47091108560562134\n","Epoch 6, Loss: 0.41942813992500305\n","Epoch 7, Loss: 0.3729766607284546\n","Epoch 8, Loss: 0.3313283920288086\n","Epoch 9, Loss: 0.29418736696243286\n","Epoch 10, Loss: 0.26121941208839417\n"]}]},{"cell_type":"markdown","source":["### 감성 분석(Sentiment Analysis) - Toy example 1\n","\n","- 실제로 학습할 만한 대규모 데이터(IMDb, 네이버 영화리뷰 등) 대신 토이(Toy) 예시를 사용했습니다.\n","- 핵심은 \"문장 전처리(토큰화) → 단어 임베딩(Embedding) → LSTM 통과 → 최종 분류\" 흐름을 이해하는 것입니다.\n","- (주의): 실제로는 학습/검증/테스트 데이터 세트를 나누고, 더 큰 말뭉치를 사용해야 성능을 제대로 낼 수 있습니다."],"metadata":{"id":"_TQ1i_v8tkki"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# ------------------------------------------------\n","# 1. 간단한 예시용 텍스트 & 레이블 설정\n","# ------------------------------------------------\n","sentences = [\n","    \"I love this movie\",\n","    \"This film was great\",\n","    \"Absolutely fantastic direction\",\n","    \"I hate this movie\",\n","    \"Terrible film ever\",\n","    \"Worst experience of my life\"\n","]\n","labels = [1, 1, 1, 0, 0, 0]  # 1: 긍정(Positive), 0: 부정(Negative)\n","\n","# ------------------------------------------------\n","# 2. 토큰화(Tokenizer) 함수 (간단히 공백 기준)\n","# ------------------------------------------------\n","def simple_tokenizer(sentence):\n","    return sentence.lower().split()\n","\n","# ------------------------------------------------\n","# 3. 어휘 사전(Vocabulary) 구축\n","#    - 실제로는 더 체계적인 전처리(불용어 제거 등)와 토큰화 기법을 사용\n","# ------------------------------------------------\n","word2idx = {\"<PAD>\": 0}  # 패딩 토큰을 0번 인덱스로\n","idx2word = {0: \"<PAD>\"}\n","\n","def build_vocab(sentences):\n","    idx = 1  # 1번 인덱스부터 실제 단어 할당\n","    for sent in sentences:\n","        tokens = simple_tokenizer(sent)\n","        for token in tokens:\n","            if token not in word2idx:\n","                word2idx[token] = idx\n","                idx2word[idx] = token\n","                idx += 1\n","\n","build_vocab(sentences)\n","vocab_size = len(word2idx)  # 총 어휘 수\n","print(\"Vocabulary Size:\", vocab_size)\n","# 예) {'<PAD>': 0, 'i':1, 'love':2, 'this':3, ... }\n","\n","# ------------------------------------------------\n","# 4. Dataset 정의\n","# ------------------------------------------------\n","class SentimentDataset(Dataset):\n","    def __init__(self, sentences, labels, max_len=5):\n","        self.sentences = sentences\n","        self.labels = labels\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        text = self.sentences[idx]\n","        label = self.labels[idx]\n","\n","        # 1) 토큰화\n","        tokens = simple_tokenizer(text)\n","\n","        # 2) 정수 인덱스로 변환\n","        token_ids = [word2idx[token] for token in tokens]\n","\n","        # 3) padding (고정 길이 max_len으로 맞춤)\n","        if len(token_ids) < self.max_len:\n","            token_ids += [0] * (self.max_len - len(token_ids))  # 0 -> <PAD>\n","        else:\n","            token_ids = token_ids[:self.max_len]\n","\n","        return {\n","            \"input_ids\": torch.tensor(token_ids, dtype=torch.long),\n","            \"label\": torch.tensor(label, dtype=torch.long)\n","        }\n","\n","# ------------------------------------------------\n","# 5. 데이터셋/데이터로더 준비\n","# ------------------------------------------------\n","dataset = SentimentDataset(sentences, labels, max_len=5)\n","dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n","\n","# ------------------------------------------------\n","# 6. 모델 정의: LSTM을 이용한 감성 분류\n","#    - 임베딩(Embedding) -> LSTM -> FC(Linear) -> 출력\n","# ------------------------------------------------\n","class LSTMSentimentClassifier(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n","        super(LSTMSentimentClassifier, self).__init__()\n","\n","        # (1) 임베딩 레이어\n","        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n","                                      embedding_dim=embed_dim,\n","                                      padding_idx=0)  # <PAD> 인덱스=0\n","\n","        # (2) LSTM 레이어\n","        self.lstm = nn.LSTM(input_size=embed_dim,\n","                            hidden_size=hidden_dim,\n","                            batch_first=True,\n","                            bidirectional=False)\n","\n","        # (3) Fully-connected (출력) 레이어\n","        self.fc = nn.Linear(in_features=hidden_dim, out_features=num_classes)\n","\n","    def forward(self, input_ids):\n","        # input_ids shape: (batch_size, seq_len)\n","\n","        # 1) 임베딩\n","        embedded = self.embedding(input_ids)\n","        # embedded shape: (batch_size, seq_len, embed_dim)\n","\n","        # 2) LSTM\n","        # LSTM은 (output, (h_n, c_n))을 반환\n","        # output shape: (batch_size, seq_len, hidden_dim)\n","        # h_n shape: (num_layers * num_directions, batch_size, hidden_dim)\n","        lstm_out, (h_n, c_n) = self.lstm(embedded)\n","\n","        # 여기서는 마지막 hidden state (h_n)을 사용해 분류\n","        # 단일 방향(single direction)이므로 h_n shape는 (1, batch, hidden_dim)\n","        # => squeeze 해주면 (batch, hidden_dim)\n","        h_n = h_n.squeeze(dim=0)  # (batch_size, hidden_dim)\n","\n","        # 3) 최종 분류\n","        logits = self.fc(h_n)  # (batch_size, num_classes)\n","        return logits\n","\n","# ------------------------------------------------\n","# 7. 모델 초기화 및 학습 셋업\n","# ------------------------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = LSTMSentimentClassifier(\n","    vocab_size=vocab_size,  # 어휘 사전 크기\n","    embed_dim=16,           # 임베딩 차원 (자유롭게)\n","    hidden_dim=8,           # LSTM hidden 차원\n","    num_classes=2           # 긍정/부정 => 2개 클래스\n",").to(device)\n","\n","criterion = nn.CrossEntropyLoss()  # 이진 분류지만, 출력을 2차원으로 -> Cross Entropy\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","# ------------------------------------------------\n","# 8. 학습 루프 (Training)\n","# ------------------------------------------------\n","num_epochs = 5\n","model.train()\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0.0\n","\n","    for batch in dataloader:\n","        input_ids = batch[\"input_ids\"].to(device)\n","        labels = batch[\"label\"].to(device)\n","\n","        # Forward\n","        logits = model(input_ids)\n","        # logits shape: (batch_size, 2)\n","\n","        loss = criterion(logits, labels)\n","\n","        # Backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_loss = total_loss / len(dataloader)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n","\n","print(\"Training finished!\\n\")\n","\n","# ------------------------------------------------\n","# 9. 간단 추론(평가)\n","# ------------------------------------------------\n","model.eval()\n","\n","test_texts = [\n","    \"I really love this film\",\n","    \"What a terrible experience\"\n","]\n","\n","with torch.no_grad():\n","    for text in test_texts:\n","        tokens = simple_tokenizer(text)\n","        token_ids = [word2idx.get(token, 0) for token in tokens]  # 없는 단어면 일단 0(<PAD>) 처리\n","\n","        # 임시로 최대 길이=5로 맞추기(패딩 또는 잘라내기)\n","        if len(token_ids) < 5:\n","            token_ids += [0]*(5-len(token_ids))\n","        else:\n","            token_ids = token_ids[:5]\n","\n","        input_tensor = torch.tensor([token_ids], dtype=torch.long).to(device)  # (1, seq_len)\n","\n","        output = model(input_tensor)  # (1, 2)\n","        pred = torch.argmax(output, dim=-1).item()\n","\n","        sentiment = \"Positive\" if pred == 1 else \"Negative\"\n","        print(f\"Text: {text}\")\n","        print(f\"Predicted sentiment: {sentiment}, Raw logits: {output.cpu().numpy()}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSieg5gxtQkd","executionInfo":{"status":"ok","timestamp":1735302308387,"user_tz":-540,"elapsed":459,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"bf4e202f-7f72-4ef3-8abb-1b1bd97109ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary Size: 19\n","Epoch [1/5], Loss: 0.7012\n","Epoch [2/5], Loss: 0.6986\n","Epoch [3/5], Loss: 0.6970\n","Epoch [4/5], Loss: 0.6954\n","Epoch [5/5], Loss: 0.6941\n","Training finished!\n","\n","Text: I really love this film\n","Predicted sentiment: Positive, Raw logits: [[-0.35132486 -0.02327562]]\n","\n","Text: What a terrible experience\n","Predicted sentiment: Positive, Raw logits: [[-0.21738939  0.06115747]]\n","\n"]}]},{"cell_type":"markdown","source":["- 위 예시는 Toy Dataset이라 실제 성능은 의미가 크지 않지만,\n","LSTM 기반 감성 분석 모델의 기본 구조(임베딩 → LSTM → 분류)를 파악하기에는 적합합니다.\n","- 실제로는 더 큰 데이터셋(IMDb, 네이버 영화리뷰 등)으로 학습/검증/테스트를 진행하고, 하이퍼파라미터(임베딩 차원, LSTM 레이어 수, 학습률 등)를 튜닝해야 합니다.\n","- 필요하다면 양방향 LSTM(Bidirectional=True), 드롭아웃(dropout), 배치 정규화 등을 추가해 모델 성능과 일반화 능력을 향상시킬 수 있습니다.\n","\n","- `nn.Embedding()` 위에서는 임베딩 벡터를 구하기 위하기 위한 임베딩 층을 직접 모델링하여 훈련하였지만, 데이터가 작은 만큼 제대로 된 임베딩 층이 학습될 수 없다.\n","- 이런 경우 사전 훈련된 임베딩(예: `GloVe`, `Word2Vec` 등)을 로드하여 임베딩 레이어에 적용할 수도 있지만,\n","- Transformer 기반의 엔드 투 엔드(End-to-end) 학습 방식의 모델(예: BERT, GPT 등)이 대세가 되면서, 전통적인 Word2Vec, GloVe 같은 사전훈련된  임베딩을 직접 불러와서 활용하는 것은 최근에는 많이 사용되지 않는다."],"metadata":{"id":"72ryw_svt5hu"}},{"cell_type":"markdown","source":["### (예제) LSTM을 이용한 네이버 영화 리뷰 분류"],"metadata":{"id":"PxpD4Nbx21zk"}},{"cell_type":"markdown","source":["이번에 사용할 데이터는 네이버 영화 리뷰 데이터입니다. 총 200,000개 리뷰로 구성된 데이터로 영화 리뷰에 대한 텍스트와 해당 리뷰가 긍정인 경우 1, 부정인 경우 0을 표시한 레이블로 구성되어져 있습니다. 해당 데이터를 다운로드 받아 감성 분류를 수행하는 모델을 만들어보겠습니다."],"metadata":{"id":"lunAGSt223KZ"}},{"cell_type":"markdown","source":["#### 4-1) 네이버 영화 리뷰 데이터에 대한 이해와 전처리\n","\n","데이터 다운로드 링크 : https://github.com/e9t/nsmc/"],"metadata":{"id":"1HfGYKjr24dB"}},{"cell_type":"code","source":["!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n","%cd Mecab-ko-for-Google-Colab\n","!bash install_mecab-ko_on_colab_light_220429.sh"],"metadata":{"id":"cBWfkjwQ26ki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import re\n","import urllib.request\n","from konlpy.tag import Mecab\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n"],"metadata":{"id":"JC5xoZhT28cP","executionInfo":{"status":"ok","timestamp":1735301109065,"user_tz":-540,"elapsed":401,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":["#### 4-1-1) 데이터 로드하기\n","\n","위 링크로부터 훈련 데이터에 해당하는 ratings_train.txt와 테스트 데이터에 해당하는 ratings_test.txt를 다운로드합니다."],"metadata":{"id":"y1gavLCJ25iy"}},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n"],"metadata":{"id":"jQEXYvRA3A6x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301113532,"user_tz":-540,"elapsed":2319,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"b6192d95-82fd-41e4-b6d3-4b978a81d2d4"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('ratings_test.txt', <http.client.HTTPMessage at 0x7db1ab556800>)"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["pandas를 이용하여 훈련 데이터는 train_data에 테스트 데이터는 test_data에 저장합니다."],"metadata":{"id":"Zi7rutc1XW6B"}},{"cell_type":"code","source":["train_data = pd.read_table('ratings_train.txt')\n","test_data = pd.read_table('ratings_test.txt')\n"],"metadata":{"id":"mPPlVtZzXX-6","executionInfo":{"status":"ok","timestamp":1735301116783,"user_tz":-540,"elapsed":1427,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":["train_data에 존재하는 영화 리뷰의 개수를 확인해봅시다."],"metadata":{"id":"7Wo_T2yhXaD-"}},{"cell_type":"code","source":["print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력\n"],"metadata":{"id":"g_XNJgNKXal6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301117897,"user_tz":-540,"elapsed":14,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"466d2a6e-a81d-490e-89f2-35ea65b9481c"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련용 리뷰 개수 : 150000\n"]}]},{"cell_type":"markdown","source":["train_data는 총 150,000개의 리뷰가 존재합니다. 상위 5개의 샘플을 출력해봅시다."],"metadata":{"id":"8Sti_2HNXbTR"}},{"cell_type":"code","source":["train_data[:5] # 상위 5개 출력\n"],"metadata":{"id":"Yx2fcjgyXcLC","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1735301121591,"user_tz":-540,"elapsed":491,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"4cabd436-3094-4c47-e4b7-e2c7c2f0992b"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"],"text/html":["\n","  <div id=\"df-0eeadfa4-058a-4f6c-b836-715385a7d845\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0eeadfa4-058a-4f6c-b836-715385a7d845')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0eeadfa4-058a-4f6c-b836-715385a7d845 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0eeadfa4-058a-4f6c-b836-715385a7d845');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f46468a5-7aee-4289-9337-9e90cff60eb6\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f46468a5-7aee-4289-9337-9e90cff60eb6')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f46468a5-7aee-4289-9337-9e90cff60eb6 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"train_data[:5] # \\uc0c1\\uc704 5\\uac1c \\ucd9c\\ub825\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2733060,\n        \"min\": 3819312,\n        \"max\": 10265843,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3819312,\n          6483659,\n          10265843\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\ud760...\\ud3ec\\uc2a4\\ud130\\ubcf4\\uace0 \\ucd08\\ub529\\uc601\\ud654\\uc904....\\uc624\\ubc84\\uc5f0\\uae30\\uc870\\ucc28 \\uac00\\ubccd\\uc9c0 \\uc54a\\uad6c\\ub098\",\n          \"\\uc0ac\\uc774\\ubaac\\ud398\\uadf8\\uc758 \\uc775\\uc0b4\\uc2a4\\ub7f0 \\uc5f0\\uae30\\uac00 \\ub3cb\\ubcf4\\uc600\\ub358 \\uc601\\ud654!\\uc2a4\\ud30c\\uc774\\ub354\\ub9e8\\uc5d0\\uc11c \\ub299\\uc5b4\\ubcf4\\uc774\\uae30\\ub9cc \\ud588\\ub358 \\ucee4\\uc2a4\\ud2f4 \\ub358\\uc2a4\\ud2b8\\uac00 \\ub108\\ubb34\\ub098\\ub3c4 \\uc774\\ubed0\\ubcf4\\uc600\\ub2e4\",\n          \"\\ub108\\ubb34\\uc7ac\\ubc13\\uc5c8\\ub2e4\\uadf8\\ub798\\uc11c\\ubcf4\\ub294\\uac83\\uc744\\ucd94\\ucc9c\\ud55c\\ub2e4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","source":["해당 데이터는 id, document, label 총 3개의 열로 구성되어져 있습니다. id는 감성 분류를 수행하는데 도움이 되지 않으므로 앞으로 무시합니다. 결국 이 모델은 리뷰 내용을 담고있는 document와 해당 리뷰가 긍정(1), 부정(0)인지를 나타내는 label 두 개의 열을 학습하는 모델이 되어야 합니다.\n","\n","또한 단지 상위 5개의 샘플만 출력해보았지만 한국어 데이터와 영어 데이터의 차이를 확인할 수 있습니다. 예를 들어, 인덱스 2번 샘플은 띄어쓰기를 하지 않아도 글을 쉽게 이해할 수 있는 한국어의 특성으로 인해 띄어쓰기가 되어있지 않습니다. test_data의 리뷰 개수와 상위 5개의 샘플을 확인해봅시다."],"metadata":{"id":"HZHzR3HMXdoS"}},{"cell_type":"code","source":["print('테스트용 리뷰 개수 :',len(test_data)) # 테스트용 리뷰 개수 출력\n"],"metadata":{"id":"mg2hinXxXej8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301123982,"user_tz":-540,"elapsed":387,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"f280454b-1ca8-4ed8-b3ae-a9796c1b8bc9"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["테스트용 리뷰 개수 : 50000\n"]}]},{"cell_type":"markdown","source":["test_data는 총 50,000개의 영화 리뷰가 존재합니다. 상위 5개의 샘플을 출력해봅시다."],"metadata":{"id":"37TUn_CHXf_x"}},{"cell_type":"code","source":["test_data[:5]"],"metadata":{"id":"nSMJzw0vXgTa","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1735301126109,"user_tz":-540,"elapsed":4,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"17668564-4a67-45cc-fb45-c8ff03044e9d"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id                                           document  label\n","0  6270596                                                굳 ㅋ      1\n","1  9274899                               GDNTOPCLASSINTHECLUB      0\n","2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n","3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n","4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"],"text/html":["\n","  <div id=\"df-2765a730-1eea-4d05-af0e-871680b26b20\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6270596</td>\n","      <td>굳 ㅋ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9274899</td>\n","      <td>GDNTOPCLASSINTHECLUB</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8544678</td>\n","      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6825595</td>\n","      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6723715</td>\n","      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2765a730-1eea-4d05-af0e-871680b26b20')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2765a730-1eea-4d05-af0e-871680b26b20 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2765a730-1eea-4d05-af0e-871680b26b20');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0aeff289-7310-414b-8805-f73f6333f44f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0aeff289-7310-414b-8805-f73f6333f44f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0aeff289-7310-414b-8805-f73f6333f44f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"test_data[:5]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1304473,\n        \"min\": 6270596,\n        \"max\": 9274899,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          9274899,\n          6723715,\n          8544678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"GDNTOPCLASSINTHECLUB\",\n          \"3D\\ub9cc \\uc544\\ub2c8\\uc5c8\\uc5b4\\ub3c4 \\ubcc4 \\ub2e4\\uc12f \\uac1c \\uc92c\\uc744\\ud150\\ub370.. \\uc65c 3D\\ub85c \\ub098\\uc640\\uc11c \\uc81c \\uc2ec\\uae30\\ub97c \\ubd88\\ud3b8\\ud558\\uac8c \\ud558\\uc8e0??\",\n          \"\\ubb50\\uc57c \\uc774 \\ud3c9\\uc810\\ub4e4\\uc740.... \\ub098\\uc058\\uc9c4 \\uc54a\\uc9c0\\ub9cc 10\\uc810 \\uc9dc\\ub9ac\\ub294 \\ub354\\ub354\\uc6b1 \\uc544\\ub2c8\\uc796\\uc544\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":69}]},{"cell_type":"markdown","source":["test_data도 train_data와 동일한 형식으로 id, document, label 3개의 열로 구성되어져 있습니다."],"metadata":{"id":"hl59IdR2XhDu"}},{"cell_type":"markdown","source":["#### 4-1-2) 데이터 정제하기\n","\n","train_data의 데이터 중복 유무를 확인합니다."],"metadata":{"id":"q6yOTUHDXiCe"}},{"cell_type":"code","source":["# document 열과 label 열의 중복을 제외한 값의 개수\n","train_data['document'].nunique(), train_data['label'].nunique()\n"],"metadata":{"id":"6M7dnC7_XmcM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301129911,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"ddf25a91-4f6d-4fe4-97f0-83446d458385"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(146182, 2)"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["총 150,000개의 샘플이 존재하는데 document열에서 중복을 제거한 샘플의 개수가 146,182개라는 것은 약 4,000개의 중복 샘플이 존재한다는 의미입니다. label 열은 0 또는 1의 두 가지 값만을 가지므로 2가 출력됩니다. 중복 샘플을 제거합니다."],"metadata":{"id":"GOqClPJRXla9"}},{"cell_type":"code","source":["# document 열의 중복 제거\n","train_data.drop_duplicates(subset=['document'], inplace=True)\n"],"metadata":{"id":"-Fw7n4vbXn2b","executionInfo":{"status":"ok","timestamp":1735301132316,"user_tz":-540,"elapsed":424,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":["중복 샘플을 제거하였습니다. 중복이 제거되었는지 전체 샘플 수를 확인합니다."],"metadata":{"id":"O-P9eVh0XpIM"}},{"cell_type":"code","source":["print('총 샘플의 수 :',len(train_data))\n"],"metadata":{"id":"2m2OyFJhXpbz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301134679,"user_tz":-540,"elapsed":409,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"1d59a65a-fd3a-4c0b-a247-fc7ac63449b3"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["총 샘플의 수 : 146183\n"]}]},{"cell_type":"markdown","source":["중복 샘플이 제거되었습니다. train_data에서 해당 리뷰의 긍, 부정 유무가 기재되어있는 레이블(label) 값의 분포를 보겠습니다."],"metadata":{"id":"1qoHDkhJXqxA"}},{"cell_type":"code","source":["train_data['label'].value_counts().plot(kind = 'bar')\n"],"metadata":{"id":"_jw5k4hvXrq1","colab":{"base_uri":"https://localhost:8080/","height":463},"executionInfo":{"status":"ok","timestamp":1735301137282,"user_tz":-540,"elapsed":476,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"fd21e440-342d-4d46-d7dc-89e624f1c997"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: xlabel='label'>"]},"metadata":{},"execution_count":73},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["앞서 확인하였듯이 약 146,000개의 영화 리뷰 샘플이 존재하는데 그래프 상으로 긍정과 부정 둘 다 약 72,000개의 샘플이 존재하여 레이블의 분포가 균일한 것처럼 보입니다. 정확하게 몇 개인지 확인해봅시다."],"metadata":{"id":"15lIeGkRXs0f"}},{"cell_type":"code","source":["print(train_data.groupby('label').size().reset_index(name = 'count'))\n"],"metadata":{"id":"ClR8GfYzXti-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301141293,"user_tz":-540,"elapsed":430,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"bbc65e5a-b3c3-4c86-bfb8-70c09d2eaa9e"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["   label  count\n","0      0  73342\n","1      1  72841\n"]}]},{"cell_type":"markdown","source":["레이블이 0인 리뷰가 근소하게 많습니다. 리뷰 중에 Null 값을 가진 샘플이 있는지 확인합니다."],"metadata":{"id":"rbYOFCR8Xuc4"}},{"cell_type":"code","source":["print(train_data.isnull().values.any())\n"],"metadata":{"id":"QnKuzgJ_XvLs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301143271,"user_tz":-540,"elapsed":903,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"02d6a81d-fcb0-49da-f4d0-7abd2118a4ba"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"cell_type":"markdown","source":["True가 나왔다면 데이터 중에 Null 값을 가진 샘플이 존재한다는 의미입니다. 어떤 열에 존재하는지 확인해봅시다."],"metadata":{"id":"1TtdVPfSXwbc"}},{"cell_type":"code","source":["print(train_data.isnull().sum())\n"],"metadata":{"id":"rijnNRZ8XxKM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301146537,"user_tz":-540,"elapsed":435,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"c9facc11-b09f-4886-912b-38bcdb8c31c1"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["id          0\n","document    1\n","label       0\n","dtype: int64\n"]}]},{"cell_type":"markdown","source":["리뷰가 적혀있는 document 열에서 Null 값을 가진 샘플이 총 1개가 존재한다고 합니다. 그렇다면 document 열에서 Null 값이 존재한다는 것을 조건으로 Null 값을 가진 샘플이 어느 인덱스의 위치에 존재하는지 한 번 출력해봅시다."],"metadata":{"id":"PW8PfhzUXyF1"}},{"cell_type":"code","source":["train_data.loc[train_data.document.isnull()]\n"],"metadata":{"id":"2US12yrXXyyU","colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"status":"ok","timestamp":1735301148938,"user_tz":-540,"elapsed":436,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"498d2dd1-d8b2-449d-e6fa-8011e90833c9"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            id document  label\n","25857  2172111      NaN      1"],"text/html":["\n","  <div id=\"df-309498ac-10b5-4bd3-ae38-252e7814a60a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25857</th>\n","      <td>2172111</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-309498ac-10b5-4bd3-ae38-252e7814a60a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-309498ac-10b5-4bd3-ae38-252e7814a60a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-309498ac-10b5-4bd3-ae38-252e7814a60a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"0"}},"metadata":{},"execution_count":77}]},{"cell_type":"markdown","source":["출력 결과는 위와 같습니다. Null 값을 가진 샘플을 제거하겠습니다."],"metadata":{"id":"4SWGite6Xz_k"}},{"cell_type":"code","source":["train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n","print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인\n"],"metadata":{"id":"DSfnGluBX1sY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301152165,"user_tz":-540,"elapsed":470,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"61692d33-8e36-4604-9cb5-7ec1a664ac0d"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"markdown","source":["Null 값을 가진 샘플이 제거되었습니다. 다시 샘플의 개수를 출력하여 1개의 샘플이 제거되었는지 확인해봅시다."],"metadata":{"id":"C-5gYKZlX3OR"}},{"cell_type":"code","source":["print(len(train_data))\n"],"metadata":{"id":"IXdTdy8AX3pN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301154598,"user_tz":-540,"elapsed":393,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"2ea9ba76-9cf0-44b3-e399-7b950c7ce060"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["146182\n"]}]},{"cell_type":"markdown","source":["데이터의 전처리를 수행해보겠습니다. 위의 train_data와 test_data에서 온점(.)이나 ?와 같은 각종 특수문자가 사용된 것을 확인했습니다. train_data로부터 한글만 남기고 제거하기 위해서 정규 표현식을 사용해보겠습니다.\n","\n","우선 영어를 예시로 정규 표현식을 설명해보겠습니다. 영어의 알파벳들을 나타내는 정규 표현식은 [a-zA-Z]입니다. 이 정규 표현식은 영어의 소문자와 대문자들을 모두 포함하고 있는 정규 표현식으로 이를 응용하면 영어에 속하지 않는 구두점이나 특수문자를 제거할 수 있습니다. 예를 들어 알파벳과 공백을 제외하고 모두 제거하는 전처리를 수행하는 예제는 다음과 같습니다."],"metadata":{"id":"-S6yfwmOX5XB"}},{"cell_type":"code","source":["#알파벳과 공백을 제외하고 모두 제거\n","eng_text = 'do!!! you expect... people~ to~ read~ the FAQ, etc. and actually accept hard~! atheism?@@'\n","print(re.sub(r'[^a-zA-Z ]', '', eng_text))\n"],"metadata":{"id":"YJYrrLCoX4ak","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301156822,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"415fa15a-fd25-4a10-844f-f4a9be1a9700"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["do you expect people to read the FAQ etc and actually accept hard atheism\n"]}]},{"cell_type":"markdown","source":["위와 같은 원리를 한국어 데이터에 적용하고 싶다면, 우선 한글을 범위 지정할 수 있는 정규 표현식을 찾아내면 되겠습니다. 우선 자음과 모음에 대한 범위를 지정해보겠습니다. 일반적으로 자음의 범위는 ㄱ ~ ㅎ, 모음의 범위는 ㅏ ~ ㅣ와 같이 지정할 수 있습니다. 해당 범위 내에 어떤 자음과 모음이 속하는지 알고 싶다면 아래의 링크를 참고하시기 바랍니다."],"metadata":{"id":"Yz0TXghVX7gp"}},{"cell_type":"markdown","source":["링크 : https://www.unicode.org/charts/PDF/U3130.pdf\n","ㄱ ~ ㅎ: 3131 ~ 314E\n","ㅏ ~ ㅣ: 314F ~ 3163\n","\n","완성형 한글의 범위는 가 ~ 힣과 같이 사용합니다. 해당 범위 내에 포함된 음절들은 아래의 링크에서 확인할 수 있습니다.\n","\n","링크 : https://www.unicode.org/charts/PDF/UAC00.pdf\n","\n","위 범위 지정을 모두 반영하여 train_data에 한글과 공백을 제외하고 모두 제거하는 정규 표현식을 수행해봅시다."],"metadata":{"id":"ljmUE_JSX8N9"}},{"cell_type":"code","source":["# 한글과 공백을 제외하고 모두 제거\n","train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", regex=True)\n","train_data[:5]"],"metadata":{"id":"GE9ufIB_YBF8","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1735301160955,"user_tz":-540,"elapsed":404,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"45f3faf6-8991-48aa-837f-20c54fc05ba6"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n","1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"],"text/html":["\n","  <div id=\"df-07333b12-1881-4fd4-9bc6-5c22e560f07c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07333b12-1881-4fd4-9bc6-5c22e560f07c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-07333b12-1881-4fd4-9bc6-5c22e560f07c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-07333b12-1881-4fd4-9bc6-5c22e560f07c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a6406fb4-629d-4370-90d2-073905ac990e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6406fb4-629d-4370-90d2-073905ac990e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a6406fb4-629d-4370-90d2-073905ac990e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"train_data[:5]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2733060,\n        \"min\": 3819312,\n        \"max\": 10265843,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3819312,\n          6483659,\n          10265843\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\ud760\\ud3ec\\uc2a4\\ud130\\ubcf4\\uace0 \\ucd08\\ub529\\uc601\\ud654\\uc904\\uc624\\ubc84\\uc5f0\\uae30\\uc870\\ucc28 \\uac00\\ubccd\\uc9c0 \\uc54a\\uad6c\\ub098\",\n          \"\\uc0ac\\uc774\\ubaac\\ud398\\uadf8\\uc758 \\uc775\\uc0b4\\uc2a4\\ub7f0 \\uc5f0\\uae30\\uac00 \\ub3cb\\ubcf4\\uc600\\ub358 \\uc601\\ud654\\uc2a4\\ud30c\\uc774\\ub354\\ub9e8\\uc5d0\\uc11c \\ub299\\uc5b4\\ubcf4\\uc774\\uae30\\ub9cc \\ud588\\ub358 \\ucee4\\uc2a4\\ud2f4 \\ub358\\uc2a4\\ud2b8\\uac00 \\ub108\\ubb34\\ub098\\ub3c4 \\uc774\\ubed0\\ubcf4\\uc600\\ub2e4\",\n          \"\\ub108\\ubb34\\uc7ac\\ubc13\\uc5c8\\ub2e4\\uadf8\\ub798\\uc11c\\ubcf4\\ub294\\uac83\\uc744\\ucd94\\ucc9c\\ud55c\\ub2e4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","source":["상위 5개의 샘플을 다시 출력해보았는데, 정규 표현식을 수행하자 기존의 공백. 즉, 띄어쓰기는 유지되면서 온점과 같은 구두점 등은 제거되었습니다. 사실 네이버 영화 리뷰는 한글이 아니더라도 영어, 숫자, 특수문자로도 리뷰를 업로드할 수 있습니다. 다시 말해 기존에 한글이 없는 리뷰였다면 더 이상 아무런 값도 없는 빈(empty) 값이 되었을 것입니다. train_data에 공백(whitespace)만 있거나 빈 값을 가진 행이 있다면 Null 값으로 변경하도록 하고, Null 값이 존재하는지 확인해보겠습니다."],"metadata":{"id":"HbP7sIpIYB-p"}},{"cell_type":"code","source":["train_data['document'] = train_data['document'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n","train_data['document'].replace('', np.nan, inplace=True)\n","print(train_data.isnull().sum())\n"],"metadata":{"id":"PuBQ9YkHYDMW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301166283,"user_tz":-540,"elapsed":406,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"9bbc44a1-d91c-48d1-838d-29e99756dcbc"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["id            0\n","document    391\n","label         0\n","dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-82-c2f9538d5bc3>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  train_data['document'].replace('', np.nan, inplace=True)\n"]}]},{"cell_type":"markdown","source":["Null 값이 789개나 새로 생겼습니다. Null 값이 있는 행을 5개만 출력해볼까요?"],"metadata":{"id":"ep5RcASjYELz"}},{"cell_type":"code","source":["train_data.loc[train_data.document.isnull()][:5]"],"metadata":{"id":"cQDS7GRDYFkH","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1735301174791,"user_tz":-540,"elapsed":407,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"e32094a0-680e-446a-e14d-755c04be4e00"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           id document  label\n","584   7117896      NaN      0\n","593   6478189      NaN      0\n","638   9364602      NaN      0\n","668   1600635      NaN      0\n","1559  6918082      NaN      1"],"text/html":["\n","  <div id=\"df-a8219f76-e381-4c3a-9ff9-497dcaea5947\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>584</th>\n","      <td>7117896</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>593</th>\n","      <td>6478189</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>638</th>\n","      <td>9364602</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>668</th>\n","      <td>1600635</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1559</th>\n","      <td>6918082</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8219f76-e381-4c3a-9ff9-497dcaea5947')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a8219f76-e381-4c3a-9ff9-497dcaea5947 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a8219f76-e381-4c3a-9ff9-497dcaea5947');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ffefd6e2-5e41-4cbb-b031-a36c220d2015\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ffefd6e2-5e41-4cbb-b031-a36c220d2015')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ffefd6e2-5e41-4cbb-b031-a36c220d2015 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"0"}},"metadata":{},"execution_count":83}]},{"cell_type":"markdown","source":["Null 샘플들은 레이블이 긍정일 수도 있고, 부정일 수도 있습니다. 아무런 의미도 없는 데이터므로 제거해줍니다."],"metadata":{"id":"zc3RwuKLX9Qd"}},{"cell_type":"code","source":["train_data = train_data.dropna(how = 'any')\n","print(len(train_data))\n"],"metadata":{"id":"xOmIg_4BYHNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301178988,"user_tz":-540,"elapsed":398,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"9663ef9e-7535-4d3b-d2ed-b5c662a880c7"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["145791\n"]}]},{"cell_type":"markdown","source":["샘플 개수가 또 다시 줄어서 145,393개가 남았습니다. 테스트 데이터에 앞서 진행한 전처리 과정을 동일하게 진행합니다."],"metadata":{"id":"DAwvzsguYIUD"}},{"cell_type":"code","source":["test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n","test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n","test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n","test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n","test_data = test_data.dropna(how='any') # Null 값 제거\n","print('전처리 후 테스트용 샘플의 개수 :',len(test_data))\n"],"metadata":{"id":"5IUZvij7YJDv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301181101,"user_tz":-540,"elapsed":4,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"2ae3bbe0-5997-4646-cc20-d779c37b781e"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["전처리 후 테스트용 샘플의 개수 : 49157\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-85-c182d8fa0991>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n"]}]},{"cell_type":"markdown","source":["#### 4-1-3) 토큰화\n","\n","토큰화를 진행해봅시다. 토큰화 과정에서 불용어를 제거하겠습니다. 불용어는 정의하기 나름인데, 한국어의 조사, 접속사 등의 보편적인 불용어를 사용할 수도 있겠지만 결국 풀고자 하는 문제의 데이터를 지속 검토하면서 계속해서 추가하는 경우 또한 많습니다. 실제 현업인 상황이라면 일반적으로 아래의 불용어보다 더 많은 불용어를 사용할 수 있습니다."],"metadata":{"id":"tspr7BxrYKZr"}},{"cell_type":"code","source":["stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']\n"],"metadata":{"id":"ikMpHxOwYOkP","executionInfo":{"status":"ok","timestamp":1735301185062,"user_tz":-540,"elapsed":428,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":86,"outputs":[]},{"cell_type":"markdown","source":["여기서는 위 정도로만 불용어를 정의하고, 토큰화를 위한 형태소 분석기는 KoNLPy의 Mecab을 사용합니다. Mecab을 복습해봅시다."],"metadata":{"id":"2YlTIv6zYN0b"}},{"cell_type":"code","source":["mecab = Mecab()\n","mecab.morphs('와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔')\n","\n"],"metadata":{"id":"OZbhXMxLYQgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301187175,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"ed9b9e43-1964-4c27-b067-41abb1b277c0"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['와',\n"," '이런',\n"," '것',\n"," '도',\n"," '영화',\n"," '라고',\n"," '차라리',\n"," '뮤직',\n"," '비디오',\n"," '를',\n"," '만드',\n"," '는',\n"," '게',\n"," '나을',\n"," '뻔']"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","source":["한국어을 토큰화할 때는 영어처럼 띄어쓰기 기준으로 토큰화를 하는 것이 아니라, 주로 형태소 분석기를 사용한다고 언급한 바 있습니다. train_data에 형태소 분석기를 사용하여 토큰화를 하면서 불용어를 제거하여 X_train에 저장합니다."],"metadata":{"id":"Q1gkkVPYYP0H"}},{"cell_type":"code","source":["X_train = []\n","for sentence in tqdm(train_data['document']):\n","    tokenized_sentence = mecab.morphs(sentence) # 토큰화\n","    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n","    X_train.append(stopwords_removed_sentence)\n"],"metadata":{"id":"OKhrefcPYSuv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301207955,"user_tz":-540,"elapsed":16448,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"07651a00-64f5-414d-97d7-77a1dba599a4"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 145791/145791 [00:16<00:00, 8931.00it/s] \n"]}]},{"cell_type":"markdown","source":["상위 3개의 샘플만 출력하여 결과를 확인해봅시다."],"metadata":{"id":"74qNGf5TYR5f"}},{"cell_type":"code","source":["print(X_train[:3])\n"],"metadata":{"id":"qMU8_l5fYUJD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301321102,"user_tz":-540,"elapsed":405,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"019fb7dc-2df8-477f-d004-065660e8e424"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["[['아', '더', '빙', '진짜', '짜증', '나', '네요', '목소리'], ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍', '않', '구나'], ['너무', '재', '밓었다그래서보는것을추천한다']]\n"]}]},{"cell_type":"markdown","source":["토큰화가 진행된 것을 볼 수 있습니다. 테스트 데이터에 대해서도 동일하게 토큰화를 해줍니다."],"metadata":{"id":"6N6bZBaKYR8H"}},{"cell_type":"code","source":["X_test = []\n","for sentence in tqdm(test_data['document']):\n","    tokenized_sentence = mecab.morphs(sentence) # 토큰화\n","    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n","    X_test.append(stopwords_removed_sentence)\n"],"metadata":{"id":"Q1UMKO-uYVaf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301329781,"user_tz":-540,"elapsed":6554,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"ac7ca128-d76d-4118-b345-a786addea4b2"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 49157/49157 [00:06<00:00, 7574.70it/s]\n"]}]},{"cell_type":"markdown","source":["지금까지 훈련 데이터와 테스트 데이터에 대해서 텍스트 전처리를 진행해보았습니다. 이제 학습 데이터와 검증 데이터, 그리고 테스트 데이터를 준비해보겠습니다."],"metadata":{"id":"zI7DukHaYWGb"}},{"cell_type":"markdown","source":["#### 4-1-4) 학습 데이터, 검증 데이터, 테스트 데이터"],"metadata":{"id":"YwmnV_HrYXsr"}},{"cell_type":"markdown","source":["이미 학습 데이터와 테스트 데이터는 준비되었지만 학습하는 동안의 성능 평가를 진행할 검증 데이터가 추가로 필요합니다. 데이터프레임의 레이블 열을 별도로 분리하여 y_train과 y_test로 저장해줍니다. 이제 학습 데이터는 X_train, y_train에 저장되고, 테스트 데이터는 X_test, y_test에 저장이 될 것입니다.\n","\n","학습 데이터 중에서 20%를 분할하여 추가로 검증 데이터를 만들어줍니다. 머신 러닝 문제를 풀 때, 데이터의 분리는 주로 사이킷런에서 제공하는 train_test_split을 사용해 진행합니다. test_size에 비율을 넣어주면 기존 데이터에 대해서 해당 비율만큼 일부 데이터를 분할하여 반환합니다.\n","\n","랜덤으로 분할하는 과정에서 레이블 불균형이 발생하지 않도록, 레이블의 균형 비율을 유지하면서 분할하고 싶다면 분할 시 기존 데이터의 y데이터를 stratify의 값으로 사용하면 됩니다."],"metadata":{"id":"BzzT39rIYZ-X"}},{"cell_type":"code","source":["y_train = np.array(train_data['label'])\n","y_test = np.array(test_data['label'])\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0, stratify=y_train)\n"],"metadata":{"id":"N98OGSRhYa_P","executionInfo":{"status":"ok","timestamp":1735301334739,"user_tz":-540,"elapsed":393,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":["실제로 비율이 잘 유지되면서 분할되었는지 확인해봅시다."],"metadata":{"id":"I5u2l6pFYbsv"}},{"cell_type":"code","source":["print('--------학습 데이터의 비율-----------')\n","print(f'부정 리뷰 = {round(np.sum(y_train==0)/len(y_train) * 100,3)}%')\n","print(f'긍정 리뷰 = {round(np.count_nonzero(y_train)/len(y_train) * 100,3)}%')\n","\n","print('--------검증 데이터의 비율-----------')\n","print(f'부정 리뷰 = {round(np.sum(y_valid==0)/len(y_valid) * 100,3)}%')\n","print(f'긍정 리뷰 = {round(np.count_nonzero(y_valid)/len(y_valid) * 100,3)}%')\n","\n","print('--------테스트 데이터의 비율-----------')\n","print(f'부정 리뷰 = {round(np.sum(y_test==0)/len(y_test) * 100,3)}%')\n","print(f'긍정 리뷰 = {round(np.count_nonzero(y_test)/len(y_test) * 100,3)}%')\n"],"metadata":{"id":"3d69dvMOYcSA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301336888,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"23c49d0f-62ca-414b-bf2d-fb33492098ba"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["--------학습 데이터의 비율-----------\n","부정 리뷰 = 50.179%\n","긍정 리뷰 = 49.821%\n","--------검증 데이터의 비율-----------\n","부정 리뷰 = 50.18%\n","긍정 리뷰 = 49.82%\n","--------테스트 데이터의 비율-----------\n","부정 리뷰 = 49.73%\n","긍정 리뷰 = 50.27%\n"]}]},{"cell_type":"markdown","source":["분할 후에도 학습 데이터와 검증 데이터의 레이블 비율이 동일한 것을 확인할 수 있습니다."],"metadata":{"id":"ypItO5kdYdrP"}},{"cell_type":"markdown","source":["#### 4-1-5) 단어 집합 만들기"],"metadata":{"id":"M7SFOE1ZYeFX"}},{"cell_type":"code","source":["word_list = []\n","for sent in X_train:\n","    for word in sent:\n","      word_list.append(word)\n","\n","word_counts = Counter(word_list)\n","print('총 단어수 :', len(word_counts))\n"],"metadata":{"id":"4CEEdDUqYhMv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301341402,"user_tz":-540,"elapsed":1380,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"d6c30bcf-1100-4a88-b056-330432470510"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["총 단어수 : 45322\n"]}]},{"cell_type":"code","source":["print('훈련 데이터에서의 단어 영화의 등장 횟수 :', word_counts['영화'])\n","print('훈련 데이터에서의 단어 공감의 등장 횟수 :', word_counts['공감'])\n"],"metadata":{"id":"NteFKco4Yigv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301343915,"user_tz":-540,"elapsed":478,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"6de4bfc6-f62e-40c8-a1c9-54a49b822625"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 데이터에서의 단어 영화의 등장 횟수 : 45806\n","훈련 데이터에서의 단어 공감의 등장 횟수 : 785\n"]}]},{"cell_type":"code","source":["vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n","print('등장 빈도수 상위 10개 단어')\n","print(vocab[:10])\n"],"metadata":{"id":"U5nYtpDTYjkb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301346155,"user_tz":-540,"elapsed":4,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"2cb510ca-d454-4be5-90f4-53ae93faba41"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["등장 빈도수 상위 10개 단어\n","['영화', '보', '있', '없', '좋', '나', '었', '만', '는데', '너무']\n"]}]},{"cell_type":"code","source":["threshold = 3\n","total_cnt = len(word_counts) # 단어의 수\n","rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n","rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n","\n","# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n","for key, value in word_counts.items():\n","    total_freq = total_freq + value\n","\n","    # 단어의 등장 빈도수가 threshold보다 작으면\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value\n","\n","print('단어 집합(vocabulary)의 크기 :',total_cnt)\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n","print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n"],"metadata":{"id":"oDQqznngYk7e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301349968,"user_tz":-540,"elapsed":398,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"f27901d5-dfa7-4b27-c6d8-4909d11ec8e4"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합(vocabulary)의 크기 : 45322\n","등장 빈도가 2번 이하인 희귀 단어의 수: 26122\n","단어 집합에서 희귀 단어의 비율: 57.636467940514535\n","전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.2671991832077114\n"]}]},{"cell_type":"code","source":["# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n","vocab_size = total_cnt - rare_cnt\n","vocab = vocab[:vocab_size]\n","print('단어 집합의 크기 :', len(vocab))\n"],"metadata":{"id":"on3mGMKqYmI7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301352984,"user_tz":-540,"elapsed":891,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"ecd5d8b1-c8de-4795-ff51-8618e9dc4a98"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 집합의 크기 : 19200\n"]}]},{"cell_type":"code","source":["word_to_index = {}\n","word_to_index['<PAD>'] = 0\n","word_to_index['<UNK>'] = 1\n","\n","for index, word in enumerate(vocab) :\n","  word_to_index[word] = index + 2\n"],"metadata":{"id":"5Nz1V-x9Ym9L","executionInfo":{"status":"ok","timestamp":1735301355532,"user_tz":-540,"elapsed":489,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":98,"outputs":[]},{"cell_type":"code","source":["print('단어 <PAD>와 맵핑되는 정수 :', word_to_index['<PAD>'])\n","print('단어 <UNK>와 맵핑되는 정수 :', word_to_index['<UNK>'])\n","print('단어 영화와 맵핑되는 정수 :', word_to_index['영화'])"],"metadata":{"id":"gG5u82aEYp2f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301358294,"user_tz":-540,"elapsed":433,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"cb3c6e41-a921-4503-e41d-b4f82c8f7b92"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["단어 <PAD>와 맵핑되는 정수 : 0\n","단어 <UNK>와 맵핑되는 정수 : 1\n","단어 영화와 맵핑되는 정수 : 2\n"]}]},{"cell_type":"markdown","source":["#### 4-1-6) 정수 인코딩"],"metadata":{"id":"G1dO0H27YiAf"}},{"cell_type":"code","source":["def texts_to_sequences(tokenized_X_data, word_to_index):\n","  encoded_X_data = []\n","  for sent in tokenized_X_data:\n","    index_sequences = []\n","    for word in sent:\n","      try:\n","          index_sequences.append(word_to_index[word])\n","      except KeyError:\n","          index_sequences.append(word_to_index['<UNK>'])\n","    encoded_X_data.append(index_sequences)\n","  return encoded_X_data\n","\n","encoded_X_train = texts_to_sequences(X_train, word_to_index)\n","encoded_X_valid = texts_to_sequences(X_valid, word_to_index)\n","encoded_X_test = texts_to_sequences(X_test, word_to_index)\n"],"metadata":{"id":"V6Tm3sK5YtWf","executionInfo":{"status":"ok","timestamp":1735301363438,"user_tz":-540,"elapsed":1851,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["# 상위 샘플 2개 출력\n","for sent in encoded_X_train[:2]:\n","  print(sent)"],"metadata":{"id":"EDBIjqGLYus3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301365656,"user_tz":-540,"elapsed":5,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"eac0df69-8c47-4f80-fff6-955731893d97"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["[378, 411, 28, 45, 180, 2656, 10, 84, 9, 94, 3, 35, 93, 63]\n","[2422, 1918, 3778, 516, 1304, 737, 76, 84, 37, 2422, 842, 11882]\n"]}]},{"cell_type":"code","source":["index_to_word = {}\n","for key, value in word_to_index.items():\n","    index_to_word[value] = key"],"metadata":{"id":"KqcgfCXDYv4s","executionInfo":{"status":"ok","timestamp":1735301368633,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":102,"outputs":[]},{"cell_type":"code","source":["decoded_sample = [index_to_word[word] for word in encoded_X_train[0]]\n","print('기존의 첫번째 샘플 :', X_train[0])\n","print('복원된 첫번째 샘플 :', decoded_sample)"],"metadata":{"id":"l-rq0rIPYwhf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301372239,"user_tz":-540,"elapsed":837,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"ae1601e1-04a7-4be3-e569-69c45cd2d276"},"execution_count":103,"outputs":[{"output_type":"stream","name":"stdout","text":["기존의 첫번째 샘플 : ['나름', '신선', '했', '던', '연출', '돋보였', '는데', '년', '만', '다시', '보', '되', '니', '감동']\n","복원된 첫번째 샘플 : ['나름', '신선', '했', '던', '연출', '돋보였', '는데', '년', '만', '다시', '보', '되', '니', '감동']\n"]}]},{"cell_type":"markdown","source":["#### 4-1-7) 패딩"],"metadata":{"id":"U7RijBgvYzAb"}},{"cell_type":"code","source":["print('리뷰의 최대 길이 :',max(len(review) for review in encoded_X_train))\n","print('리뷰의 평균 길이 :',sum(map(len, encoded_X_train))/len(encoded_X_train))\n","plt.hist([len(review) for review in encoded_X_train], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"metadata":{"id":"a-3rodWaYyE_","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1735301374287,"user_tz":-540,"elapsed":896,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"5e280269-fe38-43ca-a299-0269c272bdab"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["리뷰의 최대 길이 : 74\n","리뷰의 평균 길이 : 12.277445298031415\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["def below_threshold_len(max_len, nested_list):\n","  count = 0\n","  for sentence in nested_list:\n","    if(len(sentence) <= max_len):\n","        count = count + 1\n","  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"],"metadata":{"id":"nvGnHjAjY2N3","executionInfo":{"status":"ok","timestamp":1735301376563,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["max_len = 30\n","below_threshold_len(max_len, X_train)"],"metadata":{"id":"oBTvYOkjY4Wn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301379423,"user_tz":-540,"elapsed":1384,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"c4bb8b33-b182-404a-91de-453598691212"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 샘플 중 길이가 30 이하인 샘플의 비율: 92.50977433294464\n"]}]},{"cell_type":"code","source":["def pad_sequences(sentences, max_len):\n","  features = np.zeros((len(sentences), max_len), dtype=int)\n","  for index, sentence in enumerate(sentences):\n","    if len(sentence) != 0:\n","      features[index, :len(sentence)] = np.array(sentence)[:max_len]\n","  return features\n","\n","padded_X_train = pad_sequences(encoded_X_train, max_len=max_len)\n","padded_X_valid = pad_sequences(encoded_X_valid, max_len=max_len)\n","padded_X_test = pad_sequences(encoded_X_test, max_len=max_len)\n","\n","print('훈련 데이터의 크기 :', padded_X_train.shape)\n","print('검증 데이터의 크기 :', padded_X_valid.shape)\n","print('테스트 데이터의 크기 :', padded_X_test.shape)"],"metadata":{"id":"m8OPFqJQY5O7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301383056,"user_tz":-540,"elapsed":2064,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"612d7f4b-bbb2-4884-8f1f-00e17fd620cf"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 데이터의 크기 : (116632, 30)\n","검증 데이터의 크기 : (29159, 30)\n","테스트 데이터의 크기 : (49157, 30)\n"]}]},{"cell_type":"code","source":["print('첫번째 샘플의 길이 :', len(padded_X_train[0]))\n","print('첫번째 샘플 :', padded_X_train[0])"],"metadata":{"id":"AzTMtXYIY6UT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301383454,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"b2ee5974-59ff-4d62-dbde-e900c9bd8f08"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["첫번째 샘플의 길이 : 30\n","첫번째 샘플 : [ 378  411   28   45  180 2656   10   84    9   94    3   35   93   63\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n"]}]},{"cell_type":"markdown","source":["### 4-2) LSTM을 이용한 네이버 영화 리뷰 분류 모델\n","\n","\n","이제 딥 러닝 프레임워크 PyTorch를 이용하여 LSTM 모델을 구현해봅시다."],"metadata":{"id":"yEo1YWqbY36Z"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"skILzHmVZWfK","executionInfo":{"status":"ok","timestamp":1735301386013,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}}},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":["현재 실습 환경에서 GPU를 사용 가능한지 확인합니다"],"metadata":{"id":"Va3veWKtZYBp"}},{"cell_type":"code","source":["USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","print(\"cpu와 cuda 중 다음 기기로 학습함:\", device)"],"metadata":{"id":"-gSmk8XkZYQp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735301389044,"user_tz":-540,"elapsed":381,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"c98a561b-33a7-4354-f2e1-d2a59683bebc"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu와 cuda 중 다음 기기로 학습함: cpu\n"]}]},{"cell_type":"markdown","source":["저자의 경우 Colab에서 GPU를 선택하여 실습을 진행하여 cuda라는 출력 결과를 확인했습니다. 레이블 데이터를 파이토치의 텐서 타입으로 변환합니다. 이후 훈련 데이터의 상위 5개의 레이블을 출력해보았습니다."],"metadata":{"id":"_k313WPvZZZR"}},{"cell_type":"code","source":["train_label_tensor = torch.tensor(np.array(y_train))\n","valid_label_tensor = torch.tensor(np.array(y_valid))\n","test_label_tensor = torch.tensor(np.array(y_test))\n","print(train_label_tensor[:5])"],"metadata":{"id":"-tUoCKZwZZ_p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715720839724,"user_tz":-540,"elapsed":3,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"416c4f91-d827-4c20-dbf6-ae947f3ddb90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1, 0, 0, 1, 0])\n"]}]},{"cell_type":"markdown","source":["이제 LSTM 모델을 클래스로 구현해봅시다. 각 층을 지날 때마다 각 층의 출력의 크기를 이해하는 것이 중요합니다. 예를 들어 입력은 (배치 크기, 문장 길이)의 크기를 가지는 텐서입니다. 임베딩 층을 지나고 나면 각 단어가 임베딩 벡터로 변환되면서 (배치 크기, 문장 길이, 임베딩 벡터의 차원)으로 텐서의 크기가 변환됩니다.\n","\n","이 후 LSTM의 마지막 시점의 은닉 상태(hidden state) 값을 출력층과 연결시키는 작업을 해주어야 합니다. 이때 LSTM이 출력층으로 보는 결과값의 차원은 (배치 크기, 은닉 상태의 차원)을 가져야 합니다. 마지막 시점의 은닉 상태의 값만 전달하므로 은닉 상태는 모든 시점(문장 길이)만큼 존재하는 것이 아니라 단 하나만 있습니다. 출력층은 지난 결과는 소프트맥스 회귀를 수행하므로 (배치 크기, 분류하고자하는 카테고리의 수)의 차원을 가지게 됩니다.\n","\n","그 후 각 데이터를 배치 단위로 데이터 묶음을 꺼낼 수 있는 데이터로더로 전달합니다. 정리하면 다음과 같습니다. 아직 모델을 만들지는 않았지만, 단어 벡터의 차원을 100, 배치 크기를 32, 문장 길이를 500(패딩 후), LSTM의 은닉 상태의 차원을 128로 한다고 가정해보겠습니다.\n","\n","- 단어 벡터의 차원 = 100\n","- 문장 길이 = 500\n","- 배치 크기 = 32\n","- 데이터 개수 = 2만\n","- LSTM의 은닉층의 크기 = 128\n","- 분류하고자 하는 카테고리 개수 = 2개"],"metadata":{"id":"zqTmHCcDZbmW"}},{"cell_type":"markdown","source":["위의 정보들을 고려하였을 때 모델 내부에서 데이터의 변화는 다음과 같습니다.\n","\n","- (32, 500) => 입력 데이터의 형태 => 임베딩 층 통과 후 => (32, 500, 100) => LSTM 통과 후 => (32, 128) => Softmax 출력층 통과 후 => (32, 2)"],"metadata":{"id":"7Tcs20ntZefU"}},{"cell_type":"code","source":["class TextClassifier(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n","        super(TextClassifier, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        #self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        # x: (batch_size, seq_length)\n","        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n","\n","        # LSTM은 (hidden state, cell state)의 튜플을 반환합니다\n","        lstm_out, (hidden, cell) = self.lstm(embedded)  # lstm_out: (batch_size, seq_length, hidden_dim), hidden: (1, batch_size, hidden_dim)\n","\n","        last_hidden = hidden.squeeze(0)  # (batch_size, hidden_dim)\n","        logits = self.fc(last_hidden)  # (batch_size, output_dim)\n","        return logits#self.sigmoid(logits)\n"],"metadata":{"id":"pQiSVBo2ZhaD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["훈련 데이터, 검증 데이터, 테스트 데이터에 대해서 파이토치 텐서로 변환하고 배치 단위 연산을 위해 데이터로더로 변환합니다."],"metadata":{"id":"XrMEbBV2ZiNQ"}},{"cell_type":"code","source":["encoded_train = torch.tensor(padded_X_train).to(torch.int64)\n","train_dataset = torch.utils.data.TensorDataset(encoded_train, train_label_tensor)\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=32)\n","\n","encoded_test = torch.tensor(padded_X_test).to(torch.int64)\n","test_dataset = torch.utils.data.TensorDataset(encoded_test, test_label_tensor)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=1)\n","\n","encoded_valid = torch.tensor(padded_X_valid).to(torch.int64)\n","valid_dataset = torch.utils.data.TensorDataset(encoded_valid, valid_label_tensor)\n","valid_dataloader = torch.utils.data.DataLoader(valid_dataset, shuffle=True, batch_size=1)\n"],"metadata":{"id":"PIHIRPu9Zi6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aa = nn.Embedding(vocab_size, embedding_dim=100)\n","\n","aa.weight\n","\n","#encoded_train[:3]\n","aa_result = aa(encoded_train[:3])\n","# aa(encoded_train[:3]).shape"],"metadata":{"id":"SaA_OEnQqY_A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aa2 = nn.LSTM(100, 128, batch_first=True)\n","lstm_out, (hidden,cell) = aa2(aa_result)\n","hidden.shape\n","last_hidden = hidden.squeeze(0)"],"metadata":{"id":"ysJwjvpBtED1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aa3 = nn.Linear(128, 2)\n","aa3(last_hidden)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"muCHkrWCt0n5","executionInfo":{"status":"ok","timestamp":1715717267472,"user_tz":-540,"elapsed":299,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"a9e2789d-14b2-4b82-d0ba-00be35bffb19"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0761, 0.0813],\n","        [0.0760, 0.0808],\n","        [0.0744, 0.0805]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["vocab_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUWHJfd5r4lj","executionInfo":{"status":"ok","timestamp":1715719248764,"user_tz":-540,"elapsed":238,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"43572fa4-f323-47c8-d260-4553ac72538a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19200"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","source":["훈련 데이터의 샘플 개수가 116,314개 였으므로 배치 크기를 32로 할 경우에는 116,324/32=3,635 다시 말해 32개씩 묶인 데이터 묶음이 3,635개가 생깁니다. 그리고 학습 시에는 32개씩 데이터가 들어가게 될 것입니다."],"metadata":{"id":"yezWwCWtZjz_"}},{"cell_type":"code","source":["total_batch = len(train_dataloader)\n","print('총 배치의 수 : {}'.format(total_batch))\n"],"metadata":{"id":"_bFCIIYkZkt0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715719251150,"user_tz":-540,"elapsed":256,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"8335930c-bc78-43ab-ab15-822d426c7355"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["총 배치의 수 : 3645\n"]}]},{"cell_type":"markdown","source":["모델 객체를 선언합니다."],"metadata":{"id":"_a4aSKBxZmPb"}},{"cell_type":"code","source":["embedding_dim = 100\n","hidden_dim = 128\n","output_dim = 2\n","learning_rate = 0.01\n","num_epochs = 10\n","\n","model = TextClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n","model.to(device)\n"],"metadata":{"id":"7qdwq42-ZnBz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715720886281,"user_tz":-540,"elapsed":452,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"30a56fe9-d9fd-454b-ff53-5c60d4f317bf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TextClassifier(\n","  (embedding): Embedding(19200, 100)\n","  (lstm): LSTM(100, 128, batch_first=True)\n","  (fc): Linear(in_features=128, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["임베딩 벡터의 차원은 128, 출력층의 크기(분류해야 할 카테고리의 개수)는 2로 정했습니다. 이렇게 사용자가 정해주는 값이면서 모델의 결과에 영향을 미치는 값들을 하이퍼파라미터라고 합니다. 소프트맥스 회귀를 통해 분류 문제를 진행하므로 손실 함수는 nn.CrossEntropyLoss()를 사용합니다. 파이토치로 자연어 처리를 하게 되면 가장 많이 사용하게 되는 손실 함수입니다. 하이퍼파라미터 중 하나인 학습률(learning rate)는 0.001로 정했습니다."],"metadata":{"id":"I6o1eKDQZoXY"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss() # nn.BCELoss()#\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"],"metadata":{"id":"p_4DirQMZpGE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4-3) 평가 코드 작성\n","\n","이후 평가를 진행하기 위해서 모델의 정확도를 측정하는 함수 calculate_accuracy()를 작성합니다."],"metadata":{"id":"-MlOfiUlZrBf"}},{"cell_type":"code","source":["def calculate_accuracy(logits, labels):\n","    # _, predicted = torch.max(logits, 1)\n","    predicted = torch.argmax(logits, dim=1)\n","    correct = (predicted == labels).sum().item()\n","    total = labels.size(0)\n","    accuracy = correct / total\n","    return accuracy"],"metadata":{"id":"qPIctisXZt-T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["검증 데이터와 테스트 데이터에 대한 성능을 측정하기 위한 함수 evaluate()를 작성합니다. 아래의 함수에서 model.eval()과 with torch.no_grad()를 짚어봅시다. 이 두 개는 모델 평가를 수행할 때 중요한 역할을 합니다. 각각의 의미는 다음과 같습니다.\n","\n","- model.eval(): 모델을 평가 모드로 설정합니다. 이렇게 하면 모델 내부의 모든 레이어에 대해 평가 모드가 활성화됩니다. 일부 레이어, 예를 들어 드롭아웃이나 배치 정규화는 학습과 평가 시 다르게 동작하기 때문에 이 설정이 중요합니다. 평가 모드가 설정되지 않으면, 이러한 레이어의 동작이 올바르지 않을 수 있으며, 이로 인해 평가 결과가 제대로 나오지 않을 수 있습니다.\n","\n","- with torch.no_grad(): 이 문장은 자동 미분 엔진에서 그래디언트 계산을 비활성화합니다. 평가 중에는 기울기를 계산할 필요가 없으므로, 이렇게 설정하면 메모리를 절약하고 속도를 높일 수 있습니다. 만약 이 설정이 적용되지 않으면, 평가 과정에서 그래디언트가 계산되고 메모리를 차지하게 됩니다. 그러나 평가 결과 자체에는 직접적인 영향을 주지 않습니다.\n","\n","따라서 model.eval()은 평가 시 반드시 사용해야 하며, 그렇지 않으면 평가 결과가 올바르게 나오지 않을 수 있습니다. with torch.no_grad():는 필수는 아니지만, 메모리와 속도 측면에서 권장됩니다."],"metadata":{"id":"pDwxJfVOZutI"}},{"cell_type":"code","source":["def evaluate(model, valid_dataloader, criterion, device):\n","    val_loss = 0\n","    val_correct = 0\n","    val_total = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        # 데이터로더로부터 배치 크기만큼의 데이터를 연속으로 로드\n","        for batch_X, batch_y in valid_dataloader:\n","            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","\n","            # 모델의 예측값\n","            logits = model(batch_X)\n","\n","            # 손실을 계산\n","            loss = criterion(logits, batch_y)\n","\n","            # 정확도와 손실을 계산함\n","            val_loss += loss.item()\n","            val_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n","            val_total += batch_y.size(0)\n","\n","    val_accuracy = val_correct / val_total\n","    val_loss /= len(valid_dataloader)\n","\n","    return val_loss, val_accuracy"],"metadata":{"id":"z-GDlHuPZ0Hb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4-4) 학습"],"metadata":{"id":"i3T15giyZ3l7"}},{"cell_type":"code","source":["num_epochs = 5\n","\n","# Training loop\n","best_val_loss = float('inf')\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    # Training\n","    train_loss = 0\n","    train_correct = 0\n","    train_total = 0\n","    model.train()\n","    for batch_X, batch_y in train_dataloader:\n","        # Forward pass\n","        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n","        # batch_X.shape == (batch_size, max_len)\n","        logits = model(batch_X)\n","\n","        # Compute loss\n","        loss = criterion(logits, batch_y)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Calculate training accuracy and loss\n","        train_loss += loss.item()\n","        train_correct += calculate_accuracy(logits, batch_y) * batch_y.size(0)\n","        train_total += batch_y.size(0)\n","\n","    train_accuracy = train_correct / train_total\n","    train_loss /= len(train_dataloader)\n","\n","    # Validation\n","    val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}:')\n","    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n","    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # 검증 손실이 최소일 때 체크포인트 저장\n","    if val_loss < best_val_loss:\n","        print(f'Validation loss improved from {best_val_loss:.4f} to {val_loss:.4f}. 체크포인트를 저장합니다.')\n","        best_val_loss = val_loss\n","        torch.save(model.state_dict(), 'best_model_checkpoint.pth')"],"metadata":{"id":"zy67ZAE586EM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4-5) 모델 로드 및 평가"],"metadata":{"id":"3KdasEqSZ8L7"}},{"cell_type":"code","source":["# 모델 로드\n","model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n","\n","# 모델을 device에 올립니다.\n","model.to(device)\n"],"metadata":{"id":"M_JeYuLpZ-cj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 검증 데이터에 대한 정확도와 손실 계산\n","val_loss, val_accuracy = evaluate(model, valid_dataloader, criterion, device)\n","\n","print(f'Best model validation loss: {val_loss:.4f}')\n","print(f'Best model validation accuracy: {val_accuracy:.4f}')\n"],"metadata":{"id":"ix0RYQxOZ_hf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 데이터에 대한 정확도와 손실 계산\n","test_loss, test_accuracy = evaluate(model, test_dataloader, criterion, device)\n","\n","print(f'Best model test loss: {test_loss:.4f}')\n","print(f'Best model test accuracy: {test_accuracy:.4f}')\n"],"metadata":{"id":"6Kr4JYvAaA6I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4-6) 모델 테스트"],"metadata":{"id":"RxnsJozjaBhP"}},{"cell_type":"code","source":["index_to_tag = {0 : '부정', 1 : '긍정'}\n","\n","def predict(text, model, word_to_index, index_to_tag):\n","    # Set the model to evaluation mode\n","    model.eval()\n","\n","    # Tokenize the input text\n","    tokens = mecab.morphs(text) # 토큰화\n","    tokens = [word for word in tokens if not word in stopwords] # 불용어 제거\n","    token_indices = [word_to_index.get(token, 1) for token in tokens]\n","\n","    # Convert tokens to tensor\n","    input_tensor = torch.tensor([token_indices], dtype=torch.long).to(device)  # (1, seq_length)\n","\n","    # Pass the input tensor through the model\n","    with torch.no_grad():\n","        logits = model(input_tensor)  # (1, output_dim)\n","\n","    # Get the predicted class index\n","    predicted_index = torch.argmax(logits, dim=1)\n","\n","    # Convert the predicted index to its corresponding tag\n","    predicted_tag = index_to_tag[predicted_index.item()]\n","\n","    return predicted_tag\n"],"metadata":{"id":"E818vrXeaDoz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_input = \"이 영화 개꿀잼 ㅋㅋㅋ\"\n","predict(test_input, model, word_to_index, index_to_tag)\n"],"metadata":{"id":"f6mPQMr9aFuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_input = \"이딴게 영화냐 ㅉㅉ\"\n","predict(test_input, model, word_to_index, index_to_tag)\n"],"metadata":{"id":"FBj9tgT5aG_n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_input = \"감독 뭐하는 놈이냐?\"\n","predict(test_input, model, word_to_index, index_to_tag)\n"],"metadata":{"id":"cY-GZQJTaHbD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_input = \"와 개쩐다 정말 세계관 최강자들의 영화다\"\n","predict(test_input, model, word_to_index, index_to_tag)\n"],"metadata":{"id":"GFbITt9EaIFv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Seq2Seq를 이용한 기계번역 1 - Toy example\n","\n","- 주의: 데이터가 극도로 적고, 학습 에폭도 작아, 실제 번역 성능은 의미가 없습니다. “Seq2Seq 파이프라인이 어떻게 동작하는가”를 확인하는 용도입니다.\n"],"metadata":{"id":"MQqkkbZSF5Oi"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# ------------------------------------------------\n","# 1. Toy Parallel Corpus (영어 -> 스페인어 예시)\n","#    실제로는 훨씬 큰 병렬 데이터셋 필요\n","# ------------------------------------------------\n","english_sentences = [\n","    \"i am a student\",\n","    \"you are a teacher\",\n","    \"he is a doctor\",\n","    \"she is a nurse\",\n","    \"they are students\"\n","]\n","\n","# 스페인어 문장 (단순 매칭 예시)\n","spanish_sentences = [\n","    \"yo soy un estudiante\",\n","    \"tu eres un maestro\",\n","    \"el es un doctor\",\n","    \"ella es una enfermera\",\n","    \"ellos son estudiantes\"\n","]\n","\n","# ------------------------------------------------\n","# 2. 토큰화 & 특수 토큰 정의\n","# ------------------------------------------------\n","def tokenize(sentence):\n","    return sentence.lower().split()\n","\n","SOS_TOKEN = \"<sos>\"\n","EOS_TOKEN = \"<eos>\"\n","PAD_TOKEN = \"<pad>\"\n","UNK_TOKEN = \"<unk>\"  # 사전에 없는 단어용 토큰\n","\n","# ------------------------------------------------\n","# 3. 어휘 사전(Vocabulary) 구축\n","#    - 영어, 스페인어 각각 별도 vocab 구성\n","#    - <unk> 토큰을 포함해, OOV(Out Of Vocabulary) 처리\n","# ------------------------------------------------\n","def build_vocab(sentences):\n","    tokens = set()\n","    for s in sentences:\n","        tokens.update(tokenize(s))\n","    # 토큰 집합에 특수 토큰들 추가\n","    vocab_list = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN] + sorted(list(tokens))\n","    word2idx = {w: i for i, w in enumerate(vocab_list)}\n","    idx2word = {i: w for i, w in enumerate(vocab_list)}\n","    return word2idx, idx2word\n","\n","en_word2idx, en_idx2word = build_vocab(english_sentences)\n","es_word2idx, es_idx2word = build_vocab(spanish_sentences)\n","\n","en_vocab_size = len(en_word2idx)\n","es_vocab_size = len(es_word2idx)\n","\n","print(\"English vocab size:\", en_vocab_size)\n","print(\"Spanish vocab size:\", es_vocab_size)\n","\n","# ------------------------------------------------\n","# 4. Dataset 정의\n","#    - (영어 입력 텐서, 스페인어 목표 텐서) 반환\n","# ------------------------------------------------\n","class TranslationDataset(Dataset):\n","    def __init__(self, source_sentences, target_sentences,\n","                 source_w2i, target_w2i, max_len=10):\n","        self.source_sentences = source_sentences\n","        self.target_sentences = target_sentences\n","        self.source_w2i = source_w2i\n","        self.target_w2i = target_w2i\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.source_sentences)\n","\n","    def __getitem__(self, idx):\n","        # 1) 원문/타겟 문장\n","        en_sent = self.source_sentences[idx]\n","        es_sent = self.target_sentences[idx]\n","\n","        # 2) 토큰화\n","        en_tokens = tokenize(en_sent)\n","        es_tokens = tokenize(es_sent)\n","\n","        # 3) 스페인어 문장 끝에 <eos> 추가\n","        es_tokens = es_tokens + [EOS_TOKEN]\n","\n","        # 4) 정수 인덱스 변환 (없는 단어는 <unk>로)\n","        en_ids = [self.source_w2i.get(w, self.source_w2i[UNK_TOKEN]) for w in en_tokens]\n","        es_ids = [self.target_w2i.get(w, self.target_w2i[UNK_TOKEN]) for w in es_tokens]\n","\n","        # 5) 길이 맞춰서 패딩\n","        en_ids = en_ids[:self.max_len]\n","        es_ids = es_ids[:self.max_len]\n","\n","        en_len = len(en_ids)\n","        es_len = len(es_ids)\n","\n","        if en_len < self.max_len:\n","            en_ids += [self.source_w2i[PAD_TOKEN]] * (self.max_len - en_len)\n","        if es_len < self.max_len:\n","            es_ids += [self.target_w2i[PAD_TOKEN]] * (self.max_len - es_len)\n","\n","        # 디코더 입력: <sos> + es_ids[:-1]\n","        decoder_input = [self.target_w2i[SOS_TOKEN]] + es_ids[:-1]\n","        # 혹시 decoder_input이 max_len+1 길이가 될 수 있으니 슬라이싱\n","        decoder_input = decoder_input[:self.max_len]\n","\n","        # 다시 패딩 처리 (만약 decoder_input이 짧아졌다면)\n","        if len(decoder_input) < self.max_len:\n","            decoder_input += [self.target_w2i[PAD_TOKEN]] * (self.max_len - len(decoder_input))\n","\n","        return {\n","            \"encoder_input\": torch.tensor(en_ids, dtype=torch.long),\n","            \"decoder_input\": torch.tensor(decoder_input, dtype=torch.long),\n","            \"decoder_target\": torch.tensor(es_ids, dtype=torch.long)\n","        }\n","\n","# ------------------------------------------------\n","# 5. DataLoader\n","# ------------------------------------------------\n","dataset = TranslationDataset(\n","    english_sentences, spanish_sentences,\n","    en_word2idx, es_word2idx, max_len=8\n",")\n","dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n","\n","# ------------------------------------------------\n","# 6. Seq2Seq 모델 정의 (간단 버전, Attention 미적용)\n","# ------------------------------------------------\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim, embed_dim, hidden_dim):\n","        super(Encoder, self).__init__()\n","        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n","\n","    def forward(self, x):\n","        # x: (batch_size, seq_len)\n","        embedded = self.embedding(x)\n","        outputs, (hidden, cell) = self.lstm(embedded)\n","        return hidden, cell\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, embed_dim, hidden_dim):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(output_dim, embed_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x, hidden, cell):\n","        # x: (batch_size, seq_len)\n","        embedded = self.embedding(x)\n","        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n","        logits = self.fc(outputs)  # (batch_size, seq_len, output_dim)\n","        return logits, hidden, cell\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, encoder_input, decoder_input):\n","        # 인코더\n","        hidden, cell = self.encoder(encoder_input)\n","        # 디코더\n","        logits, hidden, cell = self.decoder(decoder_input, hidden, cell)\n","        return logits\n","\n","# ------------------------------------------------\n","# 7. 모델 초기화\n","# ------------------------------------------------\n","embed_dim = 16\n","hidden_dim = 32\n","\n","encoder = Encoder(input_dim=en_vocab_size, embed_dim=embed_dim, hidden_dim=hidden_dim)\n","decoder = Decoder(output_dim=es_vocab_size, embed_dim=embed_dim, hidden_dim=hidden_dim)\n","model = Seq2Seq(encoder, decoder)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=es_word2idx[PAD_TOKEN])\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","# ------------------------------------------------\n","# 8. 학습 루프\n","# ------------------------------------------------\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0.0\n","\n","    for batch in dataloader:\n","        enc_in = batch[\"encoder_input\"].to(device)     # (batch, seq_len)\n","        dec_in = batch[\"decoder_input\"].to(device)     # (batch, seq_len)\n","        dec_tg = batch[\"decoder_target\"].to(device)    # (batch, seq_len)\n","\n","        optimizer.zero_grad()\n","        output = model(enc_in, dec_in)  # (batch, seq_len, es_vocab_size)\n","\n","        # (batch*seq_len, vocab_size) vs (batch*seq_len)\n","        output_reshaped = output.view(-1, es_vocab_size)\n","        dec_tg_reshaped = dec_tg.view(-1)\n","\n","        loss = criterion(output_reshaped, dec_tg_reshaped)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    avg_loss = total_loss / len(dataloader)\n","    print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}\")\n","\n","print(\"Training complete!\\n\")\n","\n","# ------------------------------------------------\n","# 9. 추론(Decoding) 함수\n","# ------------------------------------------------\n","def translate(model, sentence, max_len=8):\n","    model.eval()\n","\n","    # 1) 인코더 입력 준비\n","    tokens = tokenize(sentence)\n","    en_ids = [en_word2idx.get(t, en_word2idx[UNK_TOKEN]) for t in tokens]\n","    en_ids = en_ids[:max_len]\n","    en_len = len(en_ids)\n","    if en_len < max_len:\n","        en_ids += [en_word2idx[PAD_TOKEN]]*(max_len - en_len)\n","\n","    encoder_input = torch.tensor([en_ids], dtype=torch.long).to(device)\n","\n","    # 2) 인코더 실행\n","    with torch.no_grad():\n","        hidden, cell = model.encoder(encoder_input)\n","\n","    # 3) 디코더 초기 입력: <sos>\n","    dec_input = torch.tensor([[es_word2idx[SOS_TOKEN]]], dtype=torch.long).to(device)\n","\n","    output_tokens = []\n","\n","    # 4) step-by-step 디코딩\n","    for _ in range(max_len):\n","        with torch.no_grad():\n","            logits, hidden, cell = model.decoder(dec_input, hidden, cell)\n","\n","        # 마지막 시점의 로짓\n","        pred = logits[:, -1, :]  # (1, vocab_size)\n","        pred_id = torch.argmax(pred, dim=-1).item()\n","\n","        if pred_id == es_word2idx[EOS_TOKEN]:\n","            # <eos> => 번역 종료\n","            break\n","        if pred_id == es_word2idx[PAD_TOKEN]:\n","            # <pad> => 더 이상 유효 토큰 없음\n","            break\n","\n","        output_tokens.append(pred_id)\n","\n","        # 다음 입력에 pred_id를 추가\n","        new_input = torch.cat([dec_input, torch.tensor([[pred_id]]).to(device)], dim=1)\n","        dec_input = new_input\n","\n","    # 5) 정수 -> 단어\n","    translated_words = [es_idx2word[idx] for idx in output_tokens]\n","    return \" \".join(translated_words)\n","\n","# ------------------------------------------------\n","# 10. 테스트 문장\n","#     (기존 데이터에 없는 \"doctors\" 단어 포함)\n","# ------------------------------------------------\n","test_sentences = [\n","    \"i am a teacher\",\n","    \"he is a student\",\n","    \"they are doctors\"\n","]\n","\n","for s in test_sentences:\n","    translation = translate(model, s)\n","    print(f\"English: {s}  ->  Spanish(pred): {translation}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UuBofNFGBqM","executionInfo":{"status":"ok","timestamp":1735302747979,"user_tz":-540,"elapsed":1364,"user":{"displayName":"Daewon Yang","userId":"12967305289469421565"}},"outputId":"074a766a-0e9b-4905-a3b9-131dc0da10d2"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["English vocab size: 18\n","Spanish vocab size: 20\n","[Epoch 1/10] Loss: 3.0151\n","[Epoch 2/10] Loss: 2.9992\n","[Epoch 3/10] Loss: 2.9858\n","[Epoch 4/10] Loss: 2.9579\n","[Epoch 5/10] Loss: 2.9503\n","[Epoch 6/10] Loss: 2.9280\n","[Epoch 7/10] Loss: 2.9189\n","[Epoch 8/10] Loss: 2.9092\n","[Epoch 9/10] Loss: 2.8952\n","[Epoch 10/10] Loss: 2.8708\n","Training complete!\n","\n","English: i am a teacher  ->  Spanish(pred): ellos ellos ellos ellos ellos ellos ellos ellos\n","English: he is a student  ->  Spanish(pred): ellos ellos ellos ellos ellos ellos ellos ellos\n","English: they are doctors  ->  Spanish(pred): ellos ellos ellos ellos ellos ellos ellos ellos\n"]}]},{"cell_type":"markdown","source":["### Seq2Seq를 이용한 기계번역 2\n","\n","seq2seq를 이용해서 기계 번역기를 만들어보겠습니다. 실제 서비스에 사용되는 번역기는 뒤의 챕터에서 배우게 될 어텐션 메커니즘을 사용해야 하고, 최소 수백만 개의 데이터가 필요합니다. 하지만 그럼에도 번역기를 만드는 간단한 토이 프로젝트를 사용해서 seq2seq 구조와 인코더와 디코더의 역할을 이해할 수 있습니다."],"metadata":{"id":"CdLZqgJdeE90"}},{"cell_type":"markdown","source":["### 5-3-1) 데이터 로드 및 전처리\n","\n","실제 성능이 좋은 기계 번역기를 구현하려면 방대한 데이터가 필요하므로 여기서는 seq2seq를 간단히 실습해보는 수준의 간단한 기계 번역기를 구현해보겠습니다. 기계 번역기를 훈련시키기 위해서는 훈련 데이터로 병렬 코퍼스(parallel corpus)가 필요합니다. 병렬 코퍼스란, 두 개 이상의 언어가 병렬적으로 구성된 코퍼스를 의미합니다.\n","\n","링크 : http://www.manythings.org/anki\n","\n","이번 실습에서는 프랑스어-영어 병렬 코퍼스인 fra-eng.zip 파일을 사용합니다. 위의 링크에서 해당 파일을 다운받은 후 압축을 풀면 fra.txt라는 파일을 얻을 수 있는데 해당 파일을이 실습에서 사용합니다.\n","\n","병렬 코퍼스 데이터에 대해서 이해해봅시다. 병렬 데이터라고 하면 앞서 수행한 태깅 작업 챕터의 개체명 인식과 같은 데이터를 생각할 수 있지만, 앞서 수행한 태깅 작업의 병렬 데이터와 seq2seq가 사용하는 병렬 데이터는 성격이 다릅니다. 태깅 작업의 병렬 데이터는 쌍이 되는 데이터와 레이블이 길이가 동일하였으나 여기서는 쌍이 된다고 해서 반드시 길이가 같지는 않습니다.\n","\n","실제 번역기를 생각해보면 구글 번역기에 '나는 학생이다.'라는 토큰의 개수가 2인 문장을 넣었을 때 'I am a student.'라는 토큰의 개수가 4인 문장이 나오는 것과 같은 이치입니다. seq2seq는 기본적으로 입력 시퀀스와 출력 시퀀스의 길이가 다를 수 있다고 가정합니다. 지금 구현 예제는 기계 번역기이지만 seq2seq로 구현할 수 있는 또 다른 예제인 챗봇을 만든다고 가정해보면, 대답의 길이가 질문의 길이와 항상 똑같아야 한다고하면 그 또한 이상합니다. 여기서 사용할 fra.txt 데이터는 아래와 같이 왼쪽의 영어 문장과 오른쪽의 프랑스어 문장 사이에 탭으로 구분되는 형식이 하나의 샘플입니다.\n","\n","```\n","Watch me.           Regardez-moi !\n","```"],"metadata":{"id":"wc6Xvwo3eI9g"}},{"cell_type":"markdown","source":["데이터는 위와 동일한 형식의 약 19만개의 병렬 문장 샘플을 포함하고 있습니다. 데이터를 읽고 전처리를 진행해보겠습니다. 앞으로의 코드에서 src는 source의 줄임말로 입력 문장을 나타내며, tar는 target의 줄임말로 번역하고자 하는 문장을 나타냅니다."],"metadata":{"id":"7CuKwCU3eTvE"}},{"cell_type":"code","source":["import re\n","import os\n","import unicodedata\n","import urllib3\n","import zipfile\n","import shutil\n","import numpy as np\n","import pandas as pd\n","import torch\n","from collections import Counter\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, TensorDataset\n"],"metadata":{"id":"3tgb3W-LeVLV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이번 실습에서는 약 19만개의 데이터 중 33,000개의 샘플만을 사용할 예정입니다."],"metadata":{"id":"GqN4BgGZeWlU"}},{"cell_type":"code","source":["num_samples = 33000\n"],"metadata":{"id":"PCkZE7oDeW70"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["fra-eng.zip 파일을 다운로드하고 압축을 풀겠습니다."],"metadata":{"id":"3kyiDvNKeYO6"}},{"cell_type":"code","source":["!wget -c http://www.manythings.org/anki/fra-eng.zip && unzip -o fra-eng.zip\n"],"metadata":{"id":"NmngYuADeZHE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["전처리 함수들을 구현합니다. 구두점 등을 제거하거나 단어와 구분해주기 위한 전처리입니다."],"metadata":{"id":"Yo_NQt25eaSU"}},{"cell_type":"code","source":["def unicode_to_ascii(s):\n","  # 프랑스어 악센트(accent) 삭제\n","  # 예시 : 'déjà diné' -> deja dine\n","  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n"],"metadata":{"id":"9GCxoHCGebHt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess_sentence(sent):\n","  # 악센트 삭제 함수 호출\n","  sent = unicode_to_ascii(sent.lower())\n","\n","  # 단어와 구두점 사이에 공백을 만듭니다.\n","  # Ex) \"he is a boy.\" => \"he is a boy .\"\n","  sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n","\n","  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n","  sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n","\n","  # 다수 개의 공백을 하나의 공백으로 치환\n","  sent = re.sub(r\"\\s+\", \" \", sent)\n","  return sent\n"],"metadata":{"id":"7FBya4oeeboR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_preprocessed_data():\n","  encoder_input, decoder_input, decoder_target = [], [], []\n","\n","  with open(\"fra.txt\", \"r\") as lines:\n","    for i, line in enumerate(lines):\n","      # source 데이터와 target 데이터 분리\n","      src_line, tar_line, _ = line.strip().split('\\t')\n","\n","      # source 데이터 전처리\n","      src_line = [w for w in preprocess_sentence(src_line).split()]\n","\n","      # target 데이터 전처리\n","      tar_line = preprocess_sentence(tar_line)\n","      tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n","      tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n","\n","      encoder_input.append(src_line)\n","      decoder_input.append(tar_line_in)\n","      decoder_target.append(tar_line_out)\n","\n","      if i == num_samples - 1:\n","        break\n","\n","  return encoder_input, decoder_input, decoder_target\n"],"metadata":{"id":"XtUTgv0ZecR4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["구현한 전처리 함수들을 임의의 문장을 입력으로 테스트해봅시다."],"metadata":{"id":"GJVz_WiSec7g"}},{"cell_type":"code","source":["# 전처리 테스트\n","en_sent = u\"Have you had dinner?\"\n","fr_sent = u\"Avez-vous déjà diné?\"\n","\n","print('전처리 전 영어 문장 :', en_sent)\n","print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n","print('전처리 전 프랑스어 문장 :', fr_sent)\n","print('전처리 후 프랑스어 문장 :', preprocess_sentence(fr_sent))\n"],"metadata":{"id":"HcoEeV7kedqA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n"],"metadata":{"id":"PNJBEAwGefeU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["전체 데이터에서 33,000개의 샘플에 대해서 전처리를 수행합니다. 또한 훈련 과정에서 교사 강요(Teacher Forcing)을 사용할 예정이므로, 훈련 시 사용할 디코더의 입력 시퀀스와 실제값. 즉, 레이블에 해당되는 출력 시퀀스를 따로 분리하여 저장합니다. 입력 시퀀스에는 시작을 의미하는 토큰인 를 추가하고, 출력 시퀀스에는 종료를 의미하는 토큰인 를 추가합니다. 이렇게 얻은 3개의 데이터셋 인코더의 입력, 디코더의 입력, 디코더의 레이블을 상위 5개 샘플만 출력해봅시다."],"metadata":{"id":"8WLPd20cehKk"}},{"cell_type":"code","source":["sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n","print('인코더의 입력 :',sents_en_in[:5])\n","print('디코더의 입력 :',sents_fra_in[:5])\n","print('디코더의 레이블 :',sents_fra_out[:5])\n"],"metadata":{"id":"03O15zdIehpk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델을 설계하기 전 의아한 점이 있을 수 있습니다. 현재 시점의 디코더 셀의 입력은 오직 이전 디코더 셀의 출력을 입력으로 받는다고 설명하였는데 디코더의 입력에 해당하는 데이터인 sents_fra_in이 왜 필요할까요?\n","\n","훈련 과정에서는 이전 시점의 디코더 셀의 출력을 현재 시점의 디코더 셀의 입력으로 넣어주지 않고, 이전 시점의 실제값을 현재 시점의 디코더 셀의 입력값으로 하는 방법을 사용할 겁니다. 그 이유는 이전 시점의 디코더 셀의 예측이 틀렸는데 이를 현재 시점의 디코더 셀의 입력으로 사용하면 현재 시점의 디코더 셀의 예측도 잘못될 가능성이 높고 이는 연쇄 작용으로 디코더 전체의 예측을 어렵게 합니다. 이런 상황이 반복되면 훈련 시간이 느려집니다. 만약 이 상황을 원하지 않는다면 이전 시점의 디코더 셀의 예측값 대신 실제값을 현재 시점의 디코더 셀의 입력으로 사용하는 방법을 사용할 수 있습니다. 이와 같이 RNN의 모든 시점에 대해서 이전 시점의 예측값 대신 실제값을 입력으로 주는 방법을 교사 강요라고 합니다.\n","\n","단어로부터 정수를 얻는 딕셔너리. 즉, 단어 집합(Vocabulary)을 만들어봅시다. 이를 위한 함수로 build_vocab()을 구현합니다. build_vocab은 입력된 데이터로부터 단어의 등장 빈도순으로 정렬 후에 등장 빈도가 높은 순서일 수록 낮은 정수를 부여합니다. 이때, 패딩 토큰을 위한 <PAD> 토큰은 0번, OOV에 대응하기 위한 <UNK> 토큰은 1번에 할당합니다. 이렇게 되면 빈도수가 가장 높은 단어는 정수가 2번, 빈도수가 두번 째로 많은 단어는 정수 3번이 할당됩니다."],"metadata":{"id":"blEZiH4meibI"}},{"cell_type":"code","source":["def build_vocab(sents):\n","  word_list = []\n","\n","  for sent in sents:\n","      for word in sent:\n","        word_list.append(word)\n","\n","  # 각 단어별 등장 빈도를 계산하여 등장 빈도가 높은 순서로 정렬\n","  word_counts = Counter(word_list)\n","  vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n","\n","  word_to_index = {}\n","  word_to_index['<PAD>'] = 0\n","  word_to_index['<UNK>'] = 1\n","\n","  # 등장 빈도가 높은 단어일수록 낮은 정수를 부여\n","  for index, word in enumerate(vocab) :\n","    word_to_index[word] = index + 2\n","\n","  return word_to_index\n"],"metadata":{"id":"4nJpfMn6ejq8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["영어를 위한 단어 집합 src_vocab과 프랑스어를 이용한 단어 집합 tar_vocab를 만들어봅시다. 구현 방식에 따라서는 하나의 단어 집합으로 만들어도 상관없으며 이는 선택의 차이입니다."],"metadata":{"id":"22k5DwaueksM"}},{"cell_type":"code","source":["src_vocab = build_vocab(sents_en_in)\n","tar_vocab = build_vocab(sents_fra_in + sents_fra_out)\n","\n","src_vocab_size = len(src_vocab)\n","tar_vocab_size = len(tar_vocab)\n","print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))\n"],"metadata":{"id":"1UbusGMIelc5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["정수로부터 단어를 얻는 딕셔너리를 각각 만들어줍니다. 이들은 훈련을 마치고 예측값과 실제값을 비교하는 단계에서 사용됩니다."],"metadata":{"id":"hOGSVGp1emXR"}},{"cell_type":"code","source":["index_to_src = {v: k for k, v in src_vocab.items()}\n","index_to_tar = {v: k for k, v in tar_vocab.items()}\n","\n","def texts_to_sequences(sents, word_to_index):\n","  encoded_X_data = []\n","  for sent in tqdm(sents):\n","    index_sequences = []\n","    for word in sent:\n","      try:\n","          index_sequences.append(word_to_index[word])\n","      except KeyError:\n","          index_sequences.append(word_to_index['<UNK>'])\n","    encoded_X_data.append(index_sequences)\n","  return encoded_X_data\n"],"metadata":{"id":"_TSBihczenEW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n","decoder_input = texts_to_sequences(sents_fra_in, tar_vocab)\n","decoder_target = texts_to_sequences(sents_fra_out, tar_vocab)\n"],"metadata":{"id":"0Daz3RaMen9R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 상위 5개의 샘플에 대해서 정수 인코딩 전, 후 문장 출력\n","# 인코더 입력이므로 <sos>나 <eos>가 없음\n","for i, (item1, item2) in zip(range(5), zip(sents_en_in, encoder_input)):\n","    print(f\"Index: {i}, 정수 인코딩 전: {item1}, 정수 인코딩 후: {item2}\")\n"],"metadata":{"id":"xP9nEjsFeosV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def pad_sequences(sentences, max_len=None):\n","    # 최대 길이 값이 주어지지 않을 경우 데이터 내 최대 길이로 패딩\n","    if max_len is None:\n","        max_len = max([len(sentence) for sentence in sentences])\n","\n","    features = np.zeros((len(sentences), max_len), dtype=int)\n","    for index, sentence in enumerate(sentences):\n","        if len(sentence) != 0:\n","            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n","    return features\n"],"metadata":{"id":"BPtLaKpjepgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_input = pad_sequences(encoder_input)\n","decoder_input = pad_sequences(decoder_input)\n","decoder_target = pad_sequences(decoder_target)\n"],"metadata":{"id":"A9TmdggYeqeF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["데이터의 크기(shape)를 확인합니다."],"metadata":{"id":"dSADCxTCeqoQ"}},{"cell_type":"code","source":["print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n","print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n","print('디코더의 레이블의 크기(shape) :',decoder_target.shape)\n"],"metadata":{"id":"wocagYClerqB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["테스트 데이터를 분리하기 전 데이터를 섞어줍니다. 이를 위해서 순서가 섞인 정수 시퀀스 리스트를 만듭니다."],"metadata":{"id":"O6nX0WwxeszN"}},{"cell_type":"code","source":["indices = np.arange(encoder_input.shape[0])\n","np.random.shuffle(indices)\n","print('랜덤 시퀀스 :',indices)\n"],"metadata":{"id":"UsJZH66Meth9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이를 데이터셋의 순서로 지정해주면 샘플들이 기존 순서와 다른 순서로 섞이게 됩니다."],"metadata":{"id":"z6uhrEsGeuZE"}},{"cell_type":"code","source":["encoder_input = encoder_input[indices]\n","decoder_input = decoder_input[indices]\n","decoder_target = decoder_target[indices]\n"],"metadata":{"id":"P1sbK5wvevYJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["임의로 30,997번째 샘플을 출력해봅시다. 이때 decoder_input과 decoder_target은 데이터의 구조상으로 앞에 붙은 <sos> 토큰과 뒤에 붙은 <eos>을 제외하면 동일한 시퀀스를 가져야 합니다."],"metadata":{"id":"IhSdb28gewPd"}},{"cell_type":"code","source":["print([index_to_src[word] for word in encoder_input[30997]])\n","print([index_to_tar[word] for word in decoder_input[30997]])\n","print([index_to_tar[word] for word in decoder_target[30997]])\n"],"metadata":{"id":"hPEAM8jiew3q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["33,000개의 10%에 해당되는 3,300개의 데이터를 테스트 데이터로 사용합니다."],"metadata":{"id":"vP-eNk-DexxC"}},{"cell_type":"code","source":["n_of_val = int(33000*0.1)\n","print('검증 데이터의 개수 :',n_of_val)\n"],"metadata":{"id":"NOOZYcXReyjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_input_train = encoder_input[:-n_of_val]\n","decoder_input_train = decoder_input[:-n_of_val]\n","decoder_target_train = decoder_target[:-n_of_val]\n","\n","encoder_input_test = encoder_input[-n_of_val:]\n","decoder_input_test = decoder_input[-n_of_val:]\n","decoder_target_test = decoder_target[-n_of_val:]\n"],"metadata":{"id":"TChm9hEFe0At"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["훈련 데이터와 테스트 데이터의 크기(shape)를 출력해봅시다."],"metadata":{"id":"zcVNKdOZe1hl"}},{"cell_type":"code","source":["print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n","print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n","print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n","print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n","print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n","print('테스트 target 레이블의 크기 :',decoder_target_test.shape)\n"],"metadata":{"id":"Fv-h4AS0e1tx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5-3-2) 기계 번역기 만들기"],"metadata":{"id":"JTm5qQVKe2j1"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","embedding_dim = 256\n","hidden_units = 256\n","\n","class Encoder(nn.Module):\n","    def __init__(self, src_vocab_size, embedding_dim, hidden_units):\n","        super(Encoder, self).__init__()\n","        self.embedding = nn.Embedding(src_vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n","\n","    def forward(self, x):\n","        # x.shape == (batch_size, seq_len, embedding_dim)\n","        x = self.embedding(x)\n","        # hidden.shape == (1, batch_size, hidden_units), cell.shape == (1, batch_size, hidden_units)\n","        _, (hidden, cell) = self.lstm(x)\n","        # 인코더의 출력은 hidden state, cell state\n","        return hidden, cell\n","\n","class Decoder(nn.Module):\n","    def __init__(self, tar_vocab_size, embedding_dim, hidden_units):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(tar_vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_units, batch_first=True)\n","        self.fc = nn.Linear(hidden_units, tar_vocab_size)\n","\n","    def forward(self, x, hidden, cell):\n","\n","        # x.shape == (batch_size, seq_len, embedding_dim)\n","        x = self.embedding(x)\n","\n","        # 디코더의 LSTM으로 인코더의 hidden state, cell state를 전달.\n","        # output.shape == (batch_size, seq_len, hidden_units)\n","        # hidden.shape == (1, batch_size, hidden_units)\n","        # cell.shape == (1, batch_size, hidden_units)\n","        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n","\n","        # output.shape: (batch_size, seq_len, tar_vocab_size)\n","        output = self.fc(output)\n","\n","        # 디코더의 출력은 예측값, hidden state, cell state\n","        return output, hidden, cell\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, trg):\n","        hidden, cell = self.encoder(src)\n","\n","        # 훈련 중에는 디코더의 출력 중 오직 output만 사용한다.\n","        output, _, _ = self.decoder(trg, hidden, cell)\n","        return output\n","\n","encoder = Encoder(src_vocab_size, embedding_dim, hidden_units)\n","decoder = Decoder(tar_vocab_size, embedding_dim, hidden_units)\n","model = Seq2Seq(encoder, decoder)\n","\n","loss_function = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(model.parameters())\n"],"metadata":{"id":"7Sg6743ue7Pd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델의 구조를 출력해봅시다."],"metadata":{"id":"RB3srrS2e9V4"}},{"cell_type":"code","source":["print(model)\n"],"metadata":{"id":"BBURQlwPe9kV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["임베딩 벡터의 차원과 LSTM의 은닉 상태의 크기를 256로 사용합니다. 디코더는 인코더의 마지막 은닉 상태로부터 초기 은닉 상태를 얻습니다. 디코더도 은닉 상태, 셀 상태를 리턴하기는 하지만 훈련 과정에서는 사용하지 않습니다. seq2seq의 디코더는 기본적으로 각 시점마다 다중 클래스 분류 문제를 풀고있습니다. 매 시점마다 프랑스어 단어 집합의 크기(tar_vocab_size)의 선택지에서 단어를 1개 선택하여 이를 이번 시점에서 예측한 단어로 택합니다. 다중 클래스 분류 문제이므로 손실 함수를 크로스 엔트로피 함수를 사용합니다."],"metadata":{"id":"p_9a0jyBe_p5"}},{"cell_type":"code","source":["def evaluation(model, dataloader, loss_function, device):\n","    model.eval()\n","    total_loss = 0.0\n","    total_correct = 0\n","    total_count = 0\n","\n","    with torch.no_grad():\n","        for encoder_inputs, decoder_inputs, decoder_targets in dataloader:\n","            encoder_inputs = encoder_inputs.to(device)\n","            decoder_inputs = decoder_inputs.to(device)\n","            decoder_targets = decoder_targets.to(device)\n","\n","            # 순방향 전파\n","            # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n","            outputs = model(encoder_inputs, decoder_inputs)\n","\n","            # 손실 계산\n","            # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n","            # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n","            loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n","            total_loss += loss.item()\n","\n","            # 정확도 계산 (패딩 토큰 제외)\n","            mask = decoder_targets != 0\n","            total_correct += ((outputs.argmax(dim=-1) == decoder_targets) * mask).sum().item()\n","            total_count += mask.sum().item()\n","\n","    return total_loss / len(dataloader), total_correct / total_count\n"],"metadata":{"id":"PnCF5J-le_-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_input_train_tensor = torch.tensor(encoder_input_train, dtype=torch.long)\n","decoder_input_train_tensor = torch.tensor(decoder_input_train, dtype=torch.long)\n","decoder_target_train_tensor = torch.tensor(decoder_target_train, dtype=torch.long)\n","\n","encoder_input_test_tensor = torch.tensor(encoder_input_test, dtype=torch.long)\n","decoder_input_test_tensor = torch.tensor(decoder_input_test, dtype=torch.long)\n","decoder_target_test_tensor = torch.tensor(decoder_target_test, dtype=torch.long)\n","\n","# 데이터셋 및 데이터로더 생성\n","batch_size = 128\n","\n","train_dataset = TensorDataset(encoder_input_train_tensor, decoder_input_train_tensor, decoder_target_train_tensor)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","valid_dataset = TensorDataset(encoder_input_test_tensor, decoder_input_test_tensor, decoder_target_test_tensor)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n","\n","# 학습 설정\n","num_epochs = 30\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n"],"metadata":{"id":"6icQ1VcpfBX5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["모델을 훈련합니다. 128개의 배치 크기(128개씩 데이터를 병렬로 학습)로 총 50 에포크 학습합니다. 검증 데이터로 훈련이 제대로 되고있는지 모니터링하겠습니다."],"metadata":{"id":"nkkx-hxFfCUU"}},{"cell_type":"code","source":["# Training loop\n","best_val_loss = float('inf')\n","\n","for epoch in range(num_epochs):\n","    # 훈련 모드\n","    model.train()\n","\n","    for encoder_inputs, decoder_inputs, decoder_targets in train_dataloader:\n","        encoder_inputs = encoder_inputs.to(device)\n","        decoder_inputs = decoder_inputs.to(device)\n","        decoder_targets = decoder_targets.to(device)\n","\n","        # 기울기 초기화\n","        optimizer.zero_grad()\n","\n","        # 순방향 전파\n","        # outputs.shape == (batch_size, seq_len, tar_vocab_size)\n","        outputs = model(encoder_inputs, decoder_inputs)\n","\n","        # 손실 계산 및 역방향 전파\n","        # outputs.view(-1, outputs.size(-1))의 shape는 (batch_size * seq_len, tar_vocab_size)\n","        # decoder_targets.view(-1)의 shape는 (batch_size * seq_len)\n","        loss = loss_function(outputs.view(-1, outputs.size(-1)), decoder_targets.view(-1))\n","        loss.backward()\n","\n","        # 가중치 업데이트\n","        optimizer.step()\n","\n","    train_loss, train_acc = evaluation(model, train_dataloader, loss_function, device)\n","    valid_loss, valid_acc = evaluation(model, valid_dataloader, loss_function, device)\n","\n","    print(f'Epoch: {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}')\n","\n","    # 검증 손실이 최소일 때 체크포인트 저장\n","    if valid_loss < best_val_loss:\n","        print(f'Validation loss improved from {best_val_loss:.4f} to {valid_loss:.4f}. 체크포인트를 저장합니다.')\n","        best_val_loss = valid_loss\n","        torch.save(model.state_dict(), 'best_model_checkpoint.pth')\n"],"metadata":{"id":"n5lS69S3fCqA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["검증 데이터 손실이 가장 최소일 때의 모델을 로드하고 다시 재평가해봅시다."],"metadata":{"id":"ye_8NgntfD60"}},{"cell_type":"code","source":["# 모델 로드\n","model.load_state_dict(torch.load('best_model_checkpoint.pth'))\n","\n","# 모델을 device에 올립니다.\n","model.to(device)\n","\n","# 검증 데이터에 대한 정확도와 손실 계산\n","val_loss, val_accuracy = evaluation(model, valid_dataloader, loss_function, device)\n","\n","print(f'Best model validation loss: {val_loss:.4f}')\n","print(f'Best model validation accuracy: {val_accuracy:.4f}')\n"],"metadata":{"id":"Qou64_Y_fGGZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["로드 후 재평가를 진행하였더니, 저장할 당시와 검증 데이터의 손실과 정확도가 동일하므로 저장 및 로드가 원활히 되었습니다. <sos>와 <eos> 토큰의 정수는 각각 3과 4입니다."],"metadata":{"id":"D67wbxNmfHlt"}},{"cell_type":"code","source":["print(tar_vocab['<sos>'])\n","print(tar_vocab['<eos>'])\n"],"metadata":{"id":"zXCDa5LXfIDR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5-3-3) seq2seq 기계 번역기 동작시키기"],"metadata":{"id":"YpW6MfLffKoU"}},{"cell_type":"markdown","source":["eq2seq는 훈련 과정(교사 강요)과 테스트 과정에서의 동작 방식이 다릅니다. 그래서 테스트 과정을 위해 모델을 다시 설계해주어야 합니다. 특히 디코더를 수정해야 합니다. 이번에는 번역 단계를 위해 모델을 수정하고 동작시켜보겠습니다.\n","\n","전체적인 번역 단계를 정리하면 아래와 같습니다.\n","\n","- (1) 번역하고자 하는 입력 문장이 인코더로 입력되어 인코더의 마지막 시점의 은닉 상태와 셀 상태를 얻습니다.\n","- (2) 인코더의 은닉 상태와 셀 상태, 그리고 토큰 <sos>를 디코더로 보냅니다.\n","- (3) 디코더가 토큰 <eos>가 나올 때까지 다음 단어를 예측하는 행동을 반복합니다."],"metadata":{"id":"pM1OPonvfNDE"}},{"cell_type":"code","source":["index_to_src = {v: k for k, v in src_vocab.items()}\n","index_to_tar = {v: k for k, v in tar_vocab.items()}\n","\n","# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq_to_src(input_seq):\n","  sentence = ''\n","  for encoded_word in input_seq:\n","    if(encoded_word != 0):\n","      sentence = sentence + index_to_src[encoded_word] + ' '\n","  return sentence\n","\n","# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq_to_tar(input_seq):\n","  sentence = ''\n","  for encoded_word in input_seq:\n","    if(encoded_word != 0 and encoded_word != tar_vocab['<sos>'] and encoded_word != tar_vocab['<eos>']):\n","      sentence = sentence + index_to_tar[encoded_word] + ' '\n","  return sentence\n"],"metadata":{"id":"MSy5YD50fROJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(encoder_input_test[25])\n","print(decoder_input_test[25])\n","print(decoder_target_test[25])\n"],"metadata":{"id":"LII5DmH_fSVB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["decode_sequence() 함수를 봅시다. 테스트 단계에서는 디코더를 매 시점 별로 컨트롤 하게 됩니다. 각 시점을 for문을 통해서 컨트롤하게 되며, 현재 시점의 예측은 다음 시점의 입력으로 사용됩니다. 여기서 사용될 변수는 decoder_input입니다."],"metadata":{"id":"GjWTEPEffTE1"}},{"cell_type":"code","source":["def decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, max_output_len, int_to_src_token, int_to_tar_token):\n","    encoder_inputs = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0).to(device)\n","\n","    # 인코더의 초기 상태 설정\n","    hidden, cell = model.encoder(encoder_inputs)\n","\n","    # 시작 토큰 <sos>을 디코더의 첫 입력으로 설정\n","    # unsqueeze(0)는 배치 차원을 추가하기 위함.\n","    decoder_input = torch.tensor([3], dtype=torch.long).unsqueeze(0).to(device)\n","\n","    decoded_tokens = []\n","\n","    # for문을 도는 것 == 디코더의 각 시점\n","    for _ in range(max_output_len):\n","        output, hidden, cell = model.decoder(decoder_input, hidden, cell)\n","\n","        # 소프트맥스 회귀를 수행. 예측 단어의 인덱스\n","        output_token = output.argmax(dim=-1).item()\n","\n","        # 종료 토큰 <eos>\n","        if output_token == 4:\n","            break\n","\n","        # 각 시점의 단어(정수)는 decoded_tokens에 누적하였다가 최종 번역 시퀀스로 리턴합니다.\n","        decoded_tokens.append(output_token)\n","\n","        # 현재 시점의 예측. 다음 시점의 입력으로 사용된다.\n","        decoder_input = torch.tensor([output_token], dtype=torch.long).unsqueeze(0).to(device)\n","\n","    return ' '.join(int_to_tar_token[token] for token in decoded_tokens)\n"],"metadata":{"id":"PTYA2o3tfUCx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["결과 확인을 위한 함수를 만듭니다. seq_to_src 함수는 영어 문장에 해당하는 정수 시퀀스를 입력받으면 정수로부터 영어 단어를 리턴하는 index_to_src를 통해 영어 문장으로 변환합니다. seq_to_tar은 프랑스어에 해당하는 정수 시퀀스를 입력받으면 정수로부터 프랑스어 단어를 리턴하는 index_to_tar을 통해 프랑스어 문장으로 변환합니다. 훈련 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력해봅시다."],"metadata":{"id":"WKA8h4gHfVOJ"}},{"cell_type":"code","source":["for seq_index in [3, 50, 100, 300, 1001]:\n","  input_seq = encoder_input_train[seq_index]\n","  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n","\n","  print(\"입력문장 :\",seq_to_src(encoder_input_train[seq_index]))\n","  print(\"정답문장 :\",seq_to_tar(decoder_input_train[seq_index]))\n","  print(\"번역문장 :\",translated_text)\n","  print(\"-\"*50)\n"],"metadata":{"id":"Jg6V_TOlfVjO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["테스트 데이터에 대해서 임의로 선택한 인덱스의 샘플의 결과를 출력해봅시다."],"metadata":{"id":"VHqNrKuxfXFd"}},{"cell_type":"code","source":["for seq_index in [3, 50, 100, 300, 1001]:\n","  input_seq = encoder_input_test[seq_index]\n","  translated_text = decode_sequence(input_seq, model, src_vocab_size, tar_vocab_size, 20, index_to_src, index_to_tar)\n","\n","  print(\"입력문장 :\",seq_to_src(encoder_input_test[seq_index]))\n","  print(\"정답문장 :\",seq_to_tar(decoder_input_test[seq_index]))\n","  print(\"번역문장 :\",translated_text)\n","  print(\"-\"*50)\n"],"metadata":{"id":"BpoDIYjxfXm4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"_n5ZX83GtQIV"}},{"cell_type":"markdown","source":[],"metadata":{"id":"EQHhGjdJtQP6"}},{"cell_type":"markdown","source":[],"metadata":{"id":"Gc6rJdj_tQXc"}}]}